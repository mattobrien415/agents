{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Test Cases for Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import uuid\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from email_assistant.email_assistant_hitl_memory import overall_workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Accept `write_email` and `schedule_meeting`\n",
    "\n",
    "Our first test examines what happens when a user accepts the agent's actions without modification. This baseline case helps us understand how the system behaves when no feedback is provided:\n",
    "\n",
    "1. We'll use the same tax planning email from our previous tests\n",
    "2. The system will classify it as \"RESPOND\" and propose scheduling a meeting\n",
    "3. We'll accept the meeting schedule without changes\n",
    "4. The agent will generate an email confirming the meeting\n",
    "5. We'll accept the email without changes\n",
    "\n",
    "This test demonstrates the default behavior of our memory-enabled system. When a user simply accepts proposed actions, we expect minimal or no memory updates since there's no explicit feedback to learn from. However, the system will still leverage existing memory (if any) when generating its responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "# Helper function to display memory content\n",
    "def display_memory_content(store, namespace=None):\n",
    "    # Display current memory content for all namespaces\n",
    "    print(\"\\n======= CURRENT MEMORY CONTENT =======\")\n",
    "    if namespace:\n",
    "        memory = store.get(namespace, \"user_preferences\")\n",
    "        if memory:\n",
    "            print(f\"\\n--- {namespace[1]} ---\")\n",
    "            print({\"preferences\": memory.value})\n",
    "        else:\n",
    "            print(f\"\\n--- {namespace[1]} ---\")\n",
    "            print(\"No memory found\")\n",
    "    else:\n",
    "        for namespace in [\n",
    "            (\"email_assistant\", \"triage_preferences\"),\n",
    "            (\"email_assistant\", \"response_preferences\"),\n",
    "            (\"email_assistant\", \"cal_preferences\"),\n",
    "            (\"email_assistant\", \"background\")\n",
    "        ]:\n",
    "            memory = store.get(namespace, \"user_preferences\")\n",
    "            if memory:\n",
    "                print(f\"\\n--- {namespace[1]} ---\")\n",
    "                print({\"preferences\": memory.value})\n",
    "            else:\n",
    "                print(f\"\\n--- {namespace[1]} ---\")\n",
    "                print(\"No memory found\")\n",
    "            print(\"=======================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respond - Meeting Request Email\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = MemorySaver()\n",
    "store = InMemoryStore()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer, store=store)\n",
    "thread_id_1 = uuid.uuid4()\n",
    "thread_config_1 = {\"configurable\": {\"thread_id\": thread_id_1}}\n",
    "\n",
    "# Run the graph until the first interrupt \n",
    "# Email will be classified as \"respond\" \n",
    "# Agent will create a schedule_meeting and write_email tool call\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_1):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after first interrupt\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Accept the schedule_meeting tool call\n",
    "\n",
    "As we examine the initial `schedule_meeting` proposal, note how the system uses existing memory to inform its decisions:\n",
    "\n",
    "1. The default calendar preferences show a preference for 30-minute meetings, though the email requests 45 minutes\n",
    "2. The agent still proposes a 45-minute meeting, respecting the sender's specific request\n",
    "3. We accept this proposal without modification to see if simple acceptance triggers any memory updates\n",
    "\n",
    "After running this step, we'll check the memory contents to confirm whether acceptance alone leads to memory updates. Simple acceptance represents the baseline user experience - the system works as intended without requiring adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_1):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Accept the write_email tool call\n",
    "\n",
    "Now we'll accept the email draft that confirms the meeting scheduling:\n",
    "\n",
    "1. The email draft is generated with knowledge of our calendar preferences\n",
    "2. It includes details about the meeting time, duration, and purpose\n",
    "3. We'll accept it without changes to complete the baseline test case\n",
    "\n",
    "After accepting, we'll check all memory stores to see if any updates occurred. As expected, simply accepting the agent's proposals doesn't provide strong learning signals - there's no clear feedback about what the user likes or dislikes about the agent's approach.\n",
    "\n",
    "The trace link shows the complete workflow execution, where we can see that the memory is used in the LLM call for response generation, but no memory updates occur, which is the expected behavior for simple acceptances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_1):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after accepting the write_email tool call\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "We can look at the full messages, and the trace: \n",
    "\n",
    "https://smith.langchain.com/public/86ff6474-29fe-452e-8829-b05a91b458eb/r\n",
    "\n",
    "You'll notice that memory is used in the LLM call to respond. \n",
    "\n",
    "But the memory store *not* updated, because we haven't added any feedback via HITL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_1)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Edit `write_email` and `schedule_meeting`\n",
    "\n",
    "This test explores how the system learns from direct edits to its proposed actions. When users modify the agent's suggestions, it creates clear, specific learning signals about their preferences:\n",
    "\n",
    "1. We'll use the same tax planning email as before\n",
    "2. When the agent proposes a 45-minute meeting, we'll edit it to:\n",
    "   - Change the duration to 30 minutes (matching our stored preference)\n",
    "   - Make the subject line more concise\n",
    "3. When the agent drafts an email, we'll edit it to be:\n",
    "   - Shorter and less formal\n",
    "   - Structured differently\n",
    "\n",
    "Edits provide the most explicit feedback about user preferences, letting the system learn exactly what changes are desired. We expect to see specific, targeted updates to our memory stores that reflect these edits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same email as before\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph with new thread\n",
    "checkpointer = MemorySaver()\n",
    "store = InMemoryStore()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer, store=store)\n",
    "thread_id_2 = uuid.uuid4()\n",
    "thread_config_2 = {\"configurable\": {\"thread_id\": thread_id_2}}\n",
    "\n",
    "# Run the graph until the first interrupt - will be classified as \"respond\" and the agent will create a write_email tool call\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_2):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after first interrupt\n",
    "display_memory_content(store,(\"email_assistant\", \"cal_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Edit the `schedule_meeting` tool call\n",
    "\n",
    "When we edit the meeting proposal, we're providing direct, explicit feedback about our preferences. This creates a significant learning opportunity for the system:\n",
    "\n",
    "1. The agent initially proposes a 45-minute meeting (the duration requested in the email)\n",
    "2. We edit it to 30 minutes and simplify the subject from \"Tax Planning Strategies Discussion\" to \"Tax Planning Discussion\"\n",
    "3. This creates clear, specific feedback about our time preferences and naming conventions\n",
    "\n",
    "After the edit, we'll check the calendar preferences memory store to see how it's updated. The memory update should capture both:\n",
    "- Our preference for shorter 30-minute meetings\n",
    "- Our preference for more concise meeting subjects\n",
    "\n",
    "The trace reveals the precise memory update logic, showing how the system analyzes the difference between its proposal and our edits to extract meaningful patterns and preferences. We can see the detailed justification for each memory update, ensuring transparency in the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now simulate user editing the schedule_meeting tool call\n",
    "print(\"\\nSimulating user editing the schedule_meeting tool call...\")\n",
    "edited_schedule_args = {\n",
    "    \"attendees\": [\"pm@client.com\", \"lance@company.com\"],\n",
    "    \"subject\": \"Tax Planning Discussion\",\n",
    "    \"duration_minutes\": 30, # Changed from 45 to 30\n",
    "    \"preferred_day\": \"2025-04-22\",\n",
    "    \"start_time\": 14 # 2pm\n",
    "}\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"edit\", \"args\": {\"args\": edited_schedule_args}}]), config=thread_config_2):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after editing schedule_meeting\n",
    "print(\"\\nChecking memory after editing schedule_meeting:\")\n",
    "display_memory_content(store,(\"email_assistant\", \"cal_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Looking at the memory after editing the calendar invitation, we can see that it's been updated with remarkably specific preferences:\n",
    "\n",
    "1. The system has identified that we prefer 30-minute meetings over longer durations\n",
    "2. It's also captured our preference for concise meeting subjects\n",
    "\n",
    "What's particularly impressive about this memory update is:\n",
    "- It doesn't just record our specific edit, but generalizes to a broader preference pattern\n",
    "- It preserves all existing memory content while adding the new information\n",
    "- It extracts multiple preference signals from a single edit interaction\n",
    "\n",
    "Now, let's edit the email draft to see how the system captures different types of communication preferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_memory_content(store,(\"email_assistant\", \"response_preferences\"))\n",
    "# Now simulate user editing the write_email tool call\n",
    "print(\"\\nSimulating user editing the write_email tool call...\")\n",
    "edited_email_args = {\n",
    "    \"to\": \"pm@client.com\",\n",
    "    \"subject\": \"Re: Tax season let's schedule call\",\n",
    "    \"content\": \"Thanks! I scheduled a 30-minute call next Thursday at 3:00 PM. Would that work for you?\\n\\nBest regards,\\nLance Martin\"\n",
    "}\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"edit\", \"args\": {\"args\": edited_email_args}}]), config=thread_config_2):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after editing write_email\n",
    "print(\"\\nChecking memory after editing write_email:\")\n",
    "display_memory_content(store,(\"email_assistant\", \"response_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Our email edit reveals even more sophisticated learning capabilities:\n",
    "\n",
    "1. We've dramatically shortened and simplified the email content\n",
    "2. We've changed the tone to be more casual\n",
    "3. We've added a question asking for confirmation rather than assuming the time works\n",
    "4. We've slightly altered the meeting details (day and time)\n",
    "\n",
    "Looking at the updated memory, we can see that the system has extracted a key insight about our communication style:\n",
    "\n",
    "```\n",
    "When scheduling a meeting, ask the recipient to confirm if the proposed time works for them, rather than assuming and stating the meeting is already scheduled.\n",
    "```\n",
    "\n",
    "This demonstrates the system's ability to:\n",
    "- Analyze our edit not just at a superficial level, but to understand intent\n",
    "- Extract generalizable principles from specific examples\n",
    "- Preserve all existing guidance while adding new insights\n",
    "- Maintain the organization and structure of the memory\n",
    "\n",
    "These targeted, high-quality memory updates will improve all future interactions without requiring repeated corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_2)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Ignore `write_email`, `schedule_meeting`, and `question`\n",
    "\n",
    "This test explores how the system learns from rejection. When users ignore (reject) the agent's suggestions, it creates a strong signal about content they don't want to handle:\n",
    "\n",
    "1. We'll first test ignoring a `schedule_meeting` request entirely\n",
    "2. Then we'll test accepting a meeting but ignoring the follow-up email\n",
    "3. Finally, we'll test ignoring a `question` for a different email context\n",
    "\n",
    "These rejection signals help the system learn what types of emails and actions a user prefers not to deal with, leading to more appropriate triage decisions in the future. We expect significant updates to the triage preferences memory after each ignore action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respond - Meeting Request Email\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = MemorySaver()\n",
    "store = InMemoryStore()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer, store=store)\n",
    "thread_id_3 = uuid.uuid4()\n",
    "thread_config_3 = {\"configurable\": {\"thread_id\": thread_id_3}}\n",
    "\n",
    "# Run the graph until the first interrupt \n",
    "# Email will be classified as \"respond\" \n",
    "# Agent will create a schedule_meeting and write_email tool call\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_3):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after first interrupt\n",
    "display_memory_content(store, (\"email_assistant\", \"triage_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Ignore the `schedule_meeting` tool call\n",
    "\n",
    "When we ignore a meeting scheduling request, we're signaling that we don't want to handle this type of email through the assistant. This creates a powerful learning opportunity about our triage preferences:\n",
    "\n",
    "1. The assistant initially classified the tax planning email as \"RESPOND\"\n",
    "2. But by ignoring the scheduling request, we indicate we'd prefer not to handle this type of email\n",
    "3. The system needs to update its triage classification preferences to reflect this rejection\n",
    "\n",
    "After ignoring the request, we'll check the triage preferences memory to see how the rejection affected the system's understanding. The memory update should show a new pattern added to the \"not worth responding to\" section, specifically about tax planning calls or similar recurring discussions.\n",
    "\n",
    "The trace shows how the system processes this rejection, identifies the pattern, and updates the memory with specific justification for why this type of email should be classified differently in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user ignoring the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"ignore\"}]), config=thread_config_3):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after ignoring first tool call\n",
    "print(\"\\nChecking memory after ignoring first tool call:\")\n",
    "display_memory_content(store, (\"email_assistant\", \"triage_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Looking at the memory update after ignoring the schedule_meeting tool call, we can see a remarkable triage preference update:\n",
    "\n",
    "1. The system has added \"Client requests to schedule tax planning calls\" to the \"emails not worth responding to\" section\n",
    "2. It correctly identified the general pattern (scheduling routine calls) rather than overfitting to just this specific instance\n",
    "3. It included the parenthetical note \"(unless explicitly instructed otherwise)\" to maintain flexibility\n",
    "\n",
    "This update demonstrates the system's ability to:\n",
    "- Infer general patterns from specific instances of rejection\n",
    "- Update the triage filters that determine initial email classification\n",
    "- Preserve the organization and priority of existing preferences\n",
    "- Include appropriate qualifiers to avoid overly rigid rules\n",
    "\n",
    "Next, let's see what happens when we accept the meeting but reject the email draft:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respond - Meeting Request Email\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = MemorySaver()\n",
    "store = InMemoryStore()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer, store=store)\n",
    "thread_id_3 = uuid.uuid4()\n",
    "thread_config_3 = {\"configurable\": {\"thread_id\": thread_id_3}}\n",
    "\n",
    "# Run the graph until the first interrupt \n",
    "# Email will be classified as \"respond\" \n",
    "# Agent will create a schedule_meeting and write_email tool call\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_3):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_3):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "print(f\"\\nSimulating user ignoring the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"ignore\"}]), config=thread_config_3):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after ignoring second tool call\n",
    "print(\"\\nChecking memory after ignoring second tool call:\")\n",
    "display_memory_content(store, (\"email_assistant\", \"triage_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "When we accept the meeting but ignore the email draft, we're sending a more nuanced signal about our preferences:\n",
    "\n",
    "1. We're willing to schedule the meeting (accepting the first tool call)\n",
    "2. But we don't want to send a confirmation email about it (ignoring the second tool call)\n",
    "\n",
    "Looking at the memory update, we see another evolution of our triage preferences:\n",
    "\n",
    "```\n",
    "\"Client requests to schedule routine calls (such as tax planning or similar recurring discussions)\"\n",
    "```\n",
    "\n",
    "The system has:\n",
    "- Broadened the pattern from just \"tax planning calls\" to \"routine calls\" generally\n",
    "- Added examples in parentheses for clarity\n",
    "- Positioned this in the \"not worth responding to\" section\n",
    "- Maintained all other existing preferences\n",
    "\n",
    "This demonstrates how the memory evolves over multiple interactions, becoming increasingly accurate and generalizable with each additional data point. The system is continuously refining its understanding based on our feedback patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_3)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Now let's try an email that calls the `Question` tool\n",
    "\n",
    "For our third rejection test, we'll use a different type of email - a casual social invitation about brunch. This gives us insight into how the system learns about personal vs. professional communication preferences:\n",
    "\n",
    "1. The system classifies this personal invitation as \"RESPOND\"\n",
    "2. Rather than answering directly, it uses the Question tool to ask for clarification\n",
    "3. We'll ignore this question, indicating we don't want to handle these types of emails through the assistant\n",
    "\n",
    "This test shows how ignoring questions (not just actions) can also update our triage preferences. By rejecting the clarification attempt, we signal that this entire category of email doesn't warrant response through the assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respond - Meeting Request Email\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Partner <partner@home.com>\",\n",
    "    \"subject\": \"Meet Jim and Lisa for brunch in 3 weeks?\",\n",
    "    \"email_thread\": \"Hey, should we invite Jim and Lisa to brunch in 3 weeks? We could go to the new place on 17th that everyone is talking about.\"\n",
    "}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = MemorySaver()\n",
    "store = InMemoryStore()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer, store=store)\n",
    "thread_id_4 = uuid.uuid4()\n",
    "thread_config_4 = {\"configurable\": {\"thread_id\": thread_id_4}}\n",
    "\n",
    "# Run the graph until the first interrupt \n",
    "# Email will be classified as \"respond\" \n",
    "# Agent will create a schedule_meeting and write_email tool call\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_4):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after first interrupt for Question tool\n",
    "display_memory_content(store, (\"email_assistant\", \"triage_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "Ignore the `question` tool call\n",
    "\n",
    "When we ignore a question from the assistant about a personal social invitation, we're providing yet another type of feedback:\n",
    "\n",
    "1. The system initially tries to get clarification before responding\n",
    "2. By ignoring the question, we indicate we don't even want to engage with this type of email\n",
    "3. This suggests the entire category of social invitations should be handled differently\n",
    "\n",
    "After ignoring, we'll check the triage preferences again to see how they've evolved. We expect to see a new entry about social invitations added to the \"not worth responding to\" section.\n",
    "\n",
    "The memory update justification analyzes our rejection of the question about an informal social invitation and extracts a general pattern about our preference not to handle social invitations through the assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user ignoring the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"ignore\"}]), config=thread_config_4):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after ignoring Question tool\n",
    "print(\"\\nChecking memory after ignoring Question tool:\")\n",
    "display_memory_content(store, (\"email_assistant\", \"triage_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "Looking at the memory update after ignoring the question about brunch plans, we see another sophisticated triage preference update:\n",
    "\n",
    "```\n",
    "\"Social invitations from partner (e.g., brunch plans, casual meetups)\"\n",
    "```\n",
    "\n",
    "This demonstrates how the system:\n",
    "1. Correctly identifies personal social invitations as a distinct category\n",
    "2. Specifically notes they're from \"partner\" - showing it's learning to distinguish senders\n",
    "3. Provides examples to clarify the pattern\n",
    "4. Adds this to the \"not worth responding to\" section\n",
    "\n",
    "These three ignores have collectively taught the system quite a bit about what types of emails we prefer not to handle through the assistant:\n",
    "- Tax planning calls and routine client scheduling\n",
    "- Social invitations from partners\n",
    "- Each with appropriate specificity and generalizability\n",
    "\n",
    "In a real-world scenario, these learned preferences would ensure that similar future emails would be classified differently, saving the user time by automatically filtering out categories they've previously rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_4)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## Respond (with feedback) `write_email`, `schedule_meeting`, and `question`\n",
    "\n",
    "Our final test set explores the \"response\" feedback pattern - providing guidance without directly editing or accepting. This conversational feedback mechanism offers a middle ground between acceptance and editing:\n",
    "\n",
    "1. First, we'll test feedback for meeting scheduling by requesting:\n",
    "   - Shorter duration (30 minutes instead of 45)\n",
    "   - Afternoon meeting times (after 2pm)\n",
    "   \n",
    "2. Next, we'll test feedback for email drafting by requesting:\n",
    "   - Shorter, less formal language\n",
    "   - A specific closing statement about looking forward to the meeting\n",
    "   \n",
    "3. Finally, we'll test feedback for questions by providing:\n",
    "   - A direct answer with additional context\n",
    "   - Specific preferences (brunch location, time)\n",
    "\n",
    "This natural language feedback approach lets users guide the assistant without having to do the work themselves. We expect to see detailed memory updates that extract the general principles from our specific feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respond - Meeting Request Email\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = MemorySaver()\n",
    "store = InMemoryStore()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer, store=store)\n",
    "thread_id_5 = uuid.uuid4()\n",
    "thread_config_5 = {\"configurable\": {\"thread_id\": thread_id_5}}\n",
    "\n",
    "# Run the graph until the first interrupt \n",
    "# Email will be classified as \"respond\" \n",
    "# Agent will create a schedule_meeting and write_email tool call\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after first interrupt \n",
    "display_memory_content(store, (\"email_assistant\", \"cal_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "Provide feedback for the `schedule_meeting` tool call\n",
    "\n",
    "Instead of directly editing the meeting proposal or simply accepting it, we'll provide natural language feedback:\n",
    "\n",
    "1. We request a 30-minute meeting instead of 45 minutes\n",
    "2. We express a preference for afternoon meetings after 2pm\n",
    "3. The system must interpret this feedback and generate a new proposal\n",
    "\n",
    "This conversational approach is often more natural and efficient than direct editing, especially for mobile users or those who prefer to give high-level direction rather than detailed edits.\n",
    "\n",
    "After providing feedback, we'll examine the calendar preferences memory to see how this natural language guidance is captured. We expect to see the system extract both the meeting duration and time-of-day preferences as general principles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user providing feedback for the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"response\", \"args\": \"Please schedule this for 30 minutes instead of 45 minutes, and I prefer afternoon meetings after 2pm.\"}]), config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after providing feedback for schedule_meeting\n",
    "print(\"\\nChecking memory after providing feedback for schedule_meeting:\")\n",
    "display_memory_content(store, (\"email_assistant\", \"cal_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "Our memory check after providing feedback shows an elegantly simple calendar preference update:\n",
    "\n",
    "```\n",
    "30 minute meetings are preferred, but 15 minute meetings are also acceptable.\n",
    "Afternoon meetings after 2pm are preferred.\n",
    "```\n",
    "\n",
    "The system has:\n",
    "1. Captured both aspects of our feedback (duration and time of day)\n",
    "2. Preserved the existing preference about 15-minute meetings\n",
    "3. Added our preference for afternoon meetings after 2pm as a new line\n",
    "4. Kept the format clean and readable\n",
    "\n",
    "This natural language feedback mechanism creates the same quality of memory updates as direct editing but requires less effort from the user. The system is able to extract structured preferences from unstructured feedback, showing its ability to learn from conversational interactions.\n",
    "\n",
    "Let's accept this revised meeting proposal and move to the email draft:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after accepting schedule_meeting after feedback\n",
    "print(\"\\nChecking memory after accepting schedule_meeting after feedback:\")\n",
    "display_memory_content(store, (\"email_assistant\", \"response_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "Now provide feedback for the `write_email` tool call\n",
    "\n",
    "Similar to our meeting feedback, we'll now provide natural language guidance for the email draft:\n",
    "\n",
    "1. We request \"shorter and less formal\" language - a style preference\n",
    "2. We ask for a specific closing statement about looking forward to the meeting\n",
    "3. The system must interpret this guidance and rewrite the email accordingly\n",
    "\n",
    "After providing this feedback, we'll check the response preferences memory to see how these style and structure preferences are captured. We expect to see generalizable guidelines about email brevity, formality, and closing statements added to our preference profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user providing feedback for the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"response\", \"args\": \"Shorter and less formal. Include a closing statement about looking forward to the meeting!\"}]), config=thread_config_5):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after providing feedback for write_email\n",
    "print(\"\\nChecking memory after providing feedback for write_email:\")\n",
    "display_memory_content(store, (\"email_assistant\", \"response_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "The memory update after our email feedback shows highly sophisticated learning about both meeting scheduling and email writing preferences:\n",
    "\n",
    "1. The system has added a complete new section to the response preferences entitled \"When writing email responses\" with two key preferences:\n",
    "   - \"Favor shorter and less formal language when possible, unless the context requires formality\"\n",
    "   - \"Include a closing statement expressing that you look forward to the meeting or conversation when confirming appointments\"\n",
    "\n",
    "2. It has also added a new bullet point to the \"When responding to meeting scheduling requests\" section:\n",
    "   - \"When scheduling meetings, prefer afternoon times after 2pm when possible, and default to 30-minute durations unless otherwise specified\"\n",
    "\n",
    "This demonstrates the system's ability to:\n",
    "- Organize learned preferences into appropriate categories\n",
    "- Extract multiple insights from a single feedback instance\n",
    "- Apply meeting preferences to both calendar and email contexts\n",
    "- Capture nuance with appropriate qualifiers (\"when possible,\" \"unless otherwise specified\")\n",
    "- Maintain the hierarchical structure of the memory\n",
    "\n",
    "The resulting email shows all these preferences applied: it's shorter, less formal, includes a closing statement about looking forward to the chat, and correctly references the 30-minute meeting time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after accepting write_email after feedback\n",
    "print(\"\\nChecking memory after accepting write_email after feedback:\")\n",
    "display_memory_content(store, (\"email_assistant\", \"response_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "Look at the full message history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_5)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "Now let's try an email that calls the `Question` tool to provide feedback\n",
    "\n",
    "Our final test examines feedback for questions. When the assistant needs clarification before proceeding, users can provide detailed information beyond just answering the question:\n",
    "\n",
    "1. For the brunch invitation email, we'll provide feedback that includes:\n",
    "   - Confirmation that we want to invite the people mentioned\n",
    "   - A specific location preference (Jack's)\n",
    "   - A time preference (before 11am)\n",
    "   \n",
    "2. This gives the system multiple pieces of information:\n",
    "   - A direct answer to the question (yes, let's invite them)\n",
    "   - Additional context and preferences not explicitly asked for\n",
    "\n",
    "This tests the system's ability to process compound feedback and extract multiple data points from a single response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respond - Meeting Request Email\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Partner <partner@home.com>\",\n",
    "    \"subject\": \"Meet Jim and Lisa for brunch in 3 weeks?\",\n",
    "    \"email_thread\": \"Hey, should we invite Jim and Lisa to brunch in 3 weeks? We could go to the new place on 17th that everyone is talking about.\"\n",
    "}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = MemorySaver()\n",
    "store = InMemoryStore()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer, store=store)\n",
    "thread_id_6 = uuid.uuid4()\n",
    "thread_config_6 = {\"configurable\": {\"thread_id\": thread_id_6}}\n",
    "\n",
    "# Run the graph until the first interrupt\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_6):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after first interrupt for Question tool\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "Provide feedback for the `Question` tool call\n",
    "\n",
    "When the assistant asks about our preferences for the brunch invitation, we'll respond with rich, multi-faceted feedback:\n",
    "\n",
    "1. We confirm we want to invite Jim and Lisa\n",
    "2. We specify a location preference (Jack's, not the place on 17th)\n",
    "3. We express a time preference (before 11am)\n",
    "\n",
    "This tests the system's ability to handle compound responses that both answer the direct question and provide additional context. Note that we're not just answering \"yes\" or \"no\" - we're providing a rich context that should influence the assistant's next actions.\n",
    "\n",
    "An ideal system would use this feedback to both respond to the immediate email and update background knowledge that could be relevant for future similar social invitations. In our current implementation, we don't update background knowledge from question responses, but this would be a straightforward enhancement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user providing feedback for the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"response\", \"args\": \"Yes, let's invite them, I really like brunch at Jack's, ideally before 11am.\"}]), config=thread_config_6):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after providing feedback for Question\n",
    "print(\"\\nChecking memory after providing feedback for Question:\")\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "Currently, we don't update `background_information` when the user provides feedback for the `Question` tool, but this would be a valuable enhancement.\n",
    "\n",
    "Looking at how the system handled our question response:\n",
    "\n",
    "1. It correctly incorporated all three key pieces of information:\n",
    "   - Our affirmative decision to invite Jim and Lisa\n",
    "   - Our location preference (Jack's, not the place on 17th)\n",
    "   - Our time preference (before 11am)\n",
    "\n",
    "2. It drafted a complete email that:\n",
    "   - References reaching out to Jim and Lisa\n",
    "   - Specifies Jack's as the location\n",
    "   - Suggests a 9:00 AM time (before 11am as requested)\n",
    "   - Asks for confirmation before sending an invite\n",
    "\n",
    "This demonstrates the system's ability to extract and use detailed information from natural language feedback, even when not explicitly updating memory. The email correctly incorporates all aspects of our feedback and presents a coherent plan based on our preferences.\n",
    "\n",
    "A future enhancement could store these preferences (location preferences, time preferences for social events) in the background information memory for use in future similar situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_6):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after accepting write_email after answering Question\n",
    "print(\"\\nChecking memory after accepting write_email after answering Question:\")\n",
    "display_memory_content(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "Look at the full message history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_6)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "## Test Case for Notify Classification\n",
    "\n",
    "This test explores how memory updates when an email is initially classified as \"NOTIFY\" but the user decides it needs a response:\n",
    "\n",
    "1. The triage system initially classifies IT security updates as notifications\n",
    "2. But the user decides this particular notification warrants acknowledgment\n",
    "3. This creates a learning opportunity about which notification types need responses\n",
    "\n",
    "The \"notify\" category is designed for important information that doesn't need immediate action. But user feedback can help the system learn which subset of notifications actually do warrant responses, refining the initial classification over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notify - Important FYI Email\n",
    "email_input_notify = {\n",
    "    \"to\": \"Team Members <team@company.com>\",\n",
    "    \"author\": \"IT Department <it@company.com>\",\n",
    "    \"subject\": \"Critical Security Update\",\n",
    "    \"email_thread\": \"Dear Team,\\n\\nThis is an important security notification. We will be updating our authentication system this weekend. During the update window (Saturday 2am-4am), you will not be able to access company resources.\\n\\nPlease ensure you log out of all systems before the maintenance window.\\n\\nRegards,\\nIT Department\"\n",
    "}\n",
    "\n",
    "# Compile the graph with new thread\n",
    "checkpointer = MemorySaver()\n",
    "store = InMemoryStore()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer, store=store)\n",
    "thread_id_7 = uuid.uuid4()\n",
    "thread_config_7 = {\"configurable\": {\"thread_id\": thread_id_7}}\n",
    "\n",
    "# Run the graph until the first interrupt - should be classified as \"notify\"\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_notify}, config=thread_config_7):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after first interrupt for Notify\n",
    "display_memory_content(store, (\"email_assistant\", \"triage_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "Now simulate user deciding to respond with feedback.\n",
    "\n",
    "This test explores the reclassification pathway from \"notify\" to \"respond\":\n",
    "\n",
    "1. The system initially classifies a security update as information-only (\"notify\")\n",
    "2. We're presented with this notification without a suggested action\n",
    "3. We decide this security update actually requires acknowledgment\n",
    "4. We provide feedback indicating we want to respond and confirm our compliance\n",
    "\n",
    "This represents an important learning signal - that security notifications, particularly those requesting specific user actions, should be treated as items requiring response rather than just information.\n",
    "\n",
    "After providing this feedback, we'll check the triage preferences memory to see how this \"override\" affects future classifications. We expect to see security notifications with action requests moved into the \"worth responding to\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSimulating user deciding to respond with feedback...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"response\", \"args\": \"We should acknowledge receipt of this important notice and confirm that we'll be logged out before the maintenance window.\"}]), config=thread_config_7):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after responding with feedback to Notify\n",
    "print(\"\\nChecking memory after responding with feedback to Notify:\")\n",
    "display_memory_content(store, (\"email_assistant\", \"triage_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "The memory update after our decision to respond to a security notification shows a remarkable triage preference refinement:\n",
    "\n",
    "1. The system has added a new bullet to the \"Emails that are worth responding to\" section:\n",
    "   ```\n",
    "   \"Important security notifications from IT Department requiring acknowledgment or confirmation of action\"\n",
    "   ```\n",
    "\n",
    "2. This update demonstrates:\n",
    "   - Precision: It specifically identifies \"security notifications\" (not all IT emails)\n",
    "   - Source awareness: It's from the \"IT Department\" specifically\n",
    "   - Action trigger: It identifies notifications \"requiring acknowledgment or confirmation\"\n",
    "   - Category reorganization: It moves this from \"notify\" to \"respond\" without removing notifications entirely\n",
    "\n",
    "The system didn't just record our specific override - it analyzed the *reason* we might want to respond (acknowledging required action) and created a generalizable rule. This would ensure that future similar security notifications requesting specific user actions would be correctly classified as needing response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_7):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after accepting write_email for Notify\n",
    "print(\"\\nChecking memory after accepting write_email for Notify:\")\n",
    "display_memory_content(store, (\"email_assistant\", \"triage_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "Look at the full message history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_7)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "## Test Case for Notify + Ignore\n",
    "\n",
    "Our final test explores the opposite pattern - when a user decides notifications don't even warrant being shown:\n",
    "\n",
    "1. The system classifies a company picnic announcement as a notification\n",
    "2. The user decides this doesn't even warrant notification status\n",
    "3. This creates a signal to further refine the classification boundaries\n",
    "\n",
    "By ignoring certain types of notifications, users can teach the system which information is truly important to them versus which can be filtered out entirely. This completes the full spectrum of classification refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notify - Important FYI Email\n",
    "email_input_notify = {\n",
    "    \"to\": \"Team Members <team@company.com>\",\n",
    "    \"author\": \"HR Department <hr@company.com>\",\n",
    "    \"subject\": \"Company Picnic Next Month\",\n",
    "    \"email_thread\": \"Dear Team,\\n\\nWe're planning the annual company picnic for next month. The tentative date is Saturday, June 15th from noon to 4pm at Central Park. There will be food, games, and activities for families.\\n\\nMore details will follow in the coming weeks.\\n\\nRegards,\\nHR Department\"\n",
    "}\n",
    "\n",
    "# Compile the graph with new thread\n",
    "checkpointer = MemorySaver()\n",
    "store = InMemoryStore()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer, store=store)\n",
    "thread_id_8 = uuid.uuid4()\n",
    "thread_config_8 = {\"configurable\": {\"thread_id\": thread_id_8}}\n",
    "\n",
    "# Run the graph until the first interrupt - should be classified as \"notify\"\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_notify}, config=thread_config_8):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after first interrupt for Notify + Ignore\n",
    "display_memory_content(store, (\"email_assistant\", \"triage_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "Now simulate user deciding to ignore the notification.\n",
    "\n",
    "In this final test, we explore the downgrade pathway from \"notify\" to \"ignore\":\n",
    "\n",
    "1. The system initially classifies a company picnic announcement as \"notify\"\n",
    "2. We decide we don't even want to be notified about these social events\n",
    "3. By choosing \"ignore,\" we signal this entire category should be filtered out\n",
    "\n",
    "This represents another important learning signal - that certain types of company announcements (particularly social events) shouldn't even be surfaced as notifications, further refining our triage preferences.\n",
    "\n",
    "After ignoring, we'll check the triage preferences memory for the final time to see how this override affects future classifications. We expect to see company social events moved from the \"notify\" section to the \"not worth responding to\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSimulating user deciding to ignore the notification...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"ignore\"}]), config=thread_config_8):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")\n",
    "\n",
    "# Check memory after ignoring Notify\n",
    "print(\"\\nChecking memory after ignoring Notify:\")\n",
    "display_memory_content(store, (\"email_assistant\", \"triage_preferences\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "The final memory update completes our triage preference refinement journey:\n",
    "\n",
    "1. The system has added \"Company social event announcements (e.g., company picnic)\" to the \"Emails not worth responding to\" section\n",
    "\n",
    "2. This demonstrates:\n",
    "   - Content-based categorization: It identifies \"social event announcements\" specifically\n",
    "   - Example inclusion: It provides an example \"(company picnic)\" for clarity\n",
    "   - Category downgrade: It moves this from \"notify\" to \"not worth responding to\"\n",
    "   - Structural preservation: It maintains the original memory organization\n",
    "\n",
    "Through our series of tests, we've now explored the full spectrum of triage learning:\n",
    "- Upgrading notifications to responses (security updates)\n",
    "- Downgrading notifications to ignores (company social events)\n",
    "- Downgrading responses to ignores (personal social invitations, routine calls)\n",
    "- Refining response preferences (meeting duration, timing, email style)\n",
    "\n",
    "Each interaction has produced targeted, intelligent memory updates that maintain the overall structure while adding new insights. This continuous refinement creates an increasingly personalized assistant that learns and adapts to user preferences over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_8)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "## Testing with Local Deployment\n",
    "\n",
    "You can find this graph with memory integration in the `src/email_assistant` directory:\n",
    "\n",
    "* `src/email_assistant/email_assistant_hitl_memory.py`\n",
    "\n",
    "Testing this locally gives you the full experience of a memory-enabled HITL system:\n",
    "\n",
    "1. **Start the local server**: Run `langgraph dev` to launch the agent locally\n",
    "2. **Connect Agent Inbox**: Use the graph URL from the `langgraph.json` file\n",
    "3. **Submit test emails**: Try different email types to see classification in action\n",
    "4. **Provide various feedback types**: Try accepting, editing, ignoring, and responding\n",
    "5. **Observe memory evolution**: Check the Memory tab in LangGraph Studio to see changes\n",
    "\n",
    "![inbox](img/agent-inbox-edit.png)\n",
    "\n",
    "The Memory tab in LangGraph Studio offers a real-time view of how your preferences are being captured and updated with each interaction:\n",
    "\n",
    "![studio-img](img/memory-studio.png)\n",
    "\n",
    "Through continued use, the system becomes increasingly personalized:\n",
    "- It learns which emails you want to respond to, be notified about, or ignore\n",
    "- It adapts to your communication style preferences\n",
    "- It remembers your scheduling preferences\n",
    "- It refines its understanding with each interaction\n",
    "\n",
    "This combination of HITL and memory creates a system that balances automation with control - handling routine tasks automatically while learning from your feedback to become more aligned with your preferences over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "! langgraph dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "![inbox](img/agent-inbox-edit.png)\n",
    "\n",
    "As you provide feedback or edit replies, you can see memories accumulate in the `memory` tab in LangGraph Studio.\n",
    "\n",
    "![studio-img](img/memory-studio.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "### Use LangMem to add background memory! \n",
    "\n",
    "Add this to the `llm_call` node:\n",
    "\n",
    "```\n",
    "    # Search for existing background memory\n",
    "    # TODO: Here, semantic search over a facts collection of background information from emails could be added. \n",
    "    # background = get_memory(store, (\"email_assistant\", \"background\"), default_background)\n",
    "```\n",
    "\n",
    "Add this to the interrupt handler node:\n",
    "\n",
    "```\n",
    "elif tool_call[\"name\"] == \"Question\":\n",
    "    # Don't execute the tool, and add a message with the user feedback to incorporate into the email\n",
    "    result.append({\"role\": \"tool\", \"content\": f\"User answered the question, which can we can use for any follow up actions. Feedback: {user_feedback}\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "    # TODO: Here, we could update the background information with the user's answer. \n",
    "    # update_memory(store, (\"email_assistant\", \"background\"), [{\n",
    "    #     \"role\": \"user\",\n",
    "    #     \"content\": f\"Update background information based upon these messages:\"\n",
    "    # }] + state[\"messages\"] + result)\n",
    "```\n",
    "\n",
    "Consider using LangMem: \n",
    "https://langchain-ai.github.io/langmem/"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
