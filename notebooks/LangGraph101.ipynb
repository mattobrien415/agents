{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc082433",
   "metadata": {},
   "source": [
    "# LangGraph 101\n",
    "\n",
    "[LLMs](https://python.langchain.com/docs/concepts/chat_models/) make it possible to embed intelligence into a new class of applications. LangGraph is a framework to help build applications with LLMs. Here, we will overview the basics of LangGraph, explain it's benefits, and show how it works with LangChain and LangSmith.\n",
    "\n",
    "![ecosystem](img/ecosystem.png)\n",
    "\n",
    "## Chat models\n",
    "\n",
    "[Chat models](https://python.langchain.com/docs/concepts/chat_models/) are the foundation of LLM applications. They are typically accessed through a chat model interface that takes a list of messages as input and returns a message as output. LangChain provides [a standardized interface for chat models](https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html), making it easy to [access many different providers](https://python.langchain.com/docs/integrations/chat/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecc2b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0ee8f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"openai:gpt-4.1\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50777b0b",
   "metadata": {},
   "source": [
    "## Running the model\n",
    "\n",
    "The `init_chat_model` interface also provides [standardized](https://python.langchain.com/docs/concepts/runnables/) methods for running LLMs, which include:\n",
    "- `invoke()`: Synchronously process inputs and return outputs\n",
    "- `stream()`: Return outputs [incrementally](https://python.langchain.com/docs/concepts/streaming/#stream-and-astream) as they're generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a28159d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(\"What is LangGraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41137023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc1d00eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**LangGraph** is an open-source framework designed for building stateful, multi-agent applications powered by Large Language Models (LLMs). It extends the popular [LangChain](https://www.langchain.com/) ecosystem, focusing on enabling complex workflows where multiple agents (LLMs, tools, or humans) interact in a graph-like structure.\\n\\n### Key Features\\n\\n- **Graph-based Workflows:**  \\n  LangGraph lets you define workflows as graphs, where each node can be an agent, a tool, or a function, and edges represent possible transitions based on state or output.\\n- **Stateful Interactions:**  \\n  Unlike simple chains, LangGraph maintains and updates a shared state as the workflow progresses, allowing for memory, context, and iterative reasoning.\\n- **Multi-Agent Collaboration:**  \\n  Easily orchestrate multiple agents that can communicate, collaborate, or debate to solve complex tasks.\\n- **Flexible Control Flow:**  \\n  Supports loops, branching, and conditional logic, making it suitable for advanced applications like multi-turn conversations, document analysis, or collaborative problem-solving.\\n\\n### Typical Use Cases\\n\\n- **Conversational AI:** Multi-turn, context-aware chatbots or assistants.\\n- **Agentic Workflows:** Agents that plan, execute, and reflect on tasks, possibly using tools or APIs.\\n- **Collaborative Agents:** Multiple LLMs (or LLM+human) working together, e.g., for code review, research, or negotiation.\\n\\n### Example\\n\\nA simple LangGraph workflow might look like:\\n- User input → Agent 1 (Planner) → Agent 2 (Executor) → Tool → Output\\n\\n### Resources\\n\\n- **GitHub:** [LangGraph repository](https://github.com/langchain-ai/langgraph)\\n- **Docs:** [LangGraph documentation](https://langchain-ai.github.io/langgraph/)\\n- **Announcement:** [LangChain blog post](https://blog.langchain.dev/introducing-langgraph/)\\n\\n---\\n\\n**In summary:**  \\nLangGraph is a framework for building advanced, stateful, multi-agent LLM applications using graph-based workflows, enabling more complex and interactive AI systems than simple chains or pipelines.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 432, 'prompt_tokens': 12, 'total_tokens': 444, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_cf18407276', 'id': 'chatcmpl-BTwK4OamVymNKUy4QaWpwmAFL3259', 'finish_reason': 'stop', 'logprobs': None}, id='run-3fd9d1ef-4a0a-4bed-bcbb-b97bd7737568-0', usage_metadata={'input_tokens': 12, 'output_tokens': 432, 'total_tokens': 444, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7bc6518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**LangGraph** is an open-source framework designed for building stateful, multi-agent applications powered by Large Language Models (LLMs). It extends the popular [LangChain](https://www.langchain.com/) ecosystem, focusing on enabling complex workflows where multiple agents (LLMs, tools, or humans) interact in a graph-like structure.\\n\\n### Key Features\\n\\n- **Graph-based Workflows:**  \\n  LangGraph lets you define workflows as graphs, where each node can be an agent, a tool, or a function, and edges represent possible transitions based on state or output.\\n- **Stateful Interactions:**  \\n  Unlike simple chains, LangGraph maintains and updates a shared state as the workflow progresses, allowing for memory, context, and iterative reasoning.\\n- **Multi-Agent Collaboration:**  \\n  Easily orchestrate multiple agents that can communicate, collaborate, or debate to solve complex tasks.\\n- **Flexible Control Flow:**  \\n  Supports loops, branching, and conditional logic, making it suitable for advanced applications like multi-turn conversations, document analysis, or collaborative problem-solving.\\n\\n### Typical Use Cases\\n\\n- **Conversational AI:** Multi-turn, context-aware chatbots or assistants.\\n- **Agentic Workflows:** Agents that plan, execute, and reflect on tasks, possibly using tools or APIs.\\n- **Collaborative Agents:** Multiple LLMs (or LLM+human) working together, e.g., for code review, research, or negotiation.\\n\\n### Example\\n\\nA simple LangGraph workflow might look like:\\n- User input → Agent 1 (Planner) → Agent 2 (Executor) → Tool → Output\\n\\n### Resources\\n\\n- **GitHub:** [LangGraph repository](https://github.com/langchain-ai/langgraph)\\n- **Docs:** [LangGraph documentation](https://langchain-ai.github.io/langgraph/)\\n- **Announcement:** [LangChain blog post](https://blog.langchain.dev/introducing-langgraph/)\\n\\n---\\n\\n**In summary:**  \\nLangGraph is a framework for building advanced, stateful, multi-agent LLM applications using graph-based workflows, enabling more complex and interactive AI systems than simple chains or pipelines.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a24d8ef",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "[Tools](https://python.langchain.com/docs/concepts/tools/) are utilities that can be called by a model, and whose outputs are designed to be fed back to a model. In LangChain, creating tools is simple using the `@tool` decorator, which transforms Python functions into callable tools. You can also use [Model Context Protocol (MCP) servers](https://github.com/langchain-ai/langchain-mcp-adapters) as LangChain-compatible tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afdff275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def write_email(to: str, subject: str, content: str) -> str:\n",
    "    \"\"\"Write and send an email.\"\"\"\n",
    "    # Placeholder response - in real app would send email\n",
    "    return f\"Email sent to {to} with subject '{subject}' and content: {content}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a6b427",
   "metadata": {},
   "source": [
    "## Tool Calling\n",
    "\n",
    "[Tool calling](https://python.langchain.com/docs/concepts/tool_calling/) is how models call tools to accomplish tasks. In simple terms, the model returns a schema that is required to call the tool. We use the `bind_tools` method to augment an LLM with tools.\n",
    "\n",
    "![tool-img](img/tool_call_detail.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfa57bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect tools to a chat model\n",
    "model = init_chat_model(\"openai:gpt-4.1\", temperature=0.0)\n",
    "model_with_tools = model.bind_tools([write_email], tool_choice=\"required\")\n",
    "\n",
    "# The model will now be able to call tools\n",
    "output = model_with_tools.invoke(\"Draft a response to my boss about tomorrow's meeting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "717779cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to': 'boss@example.com',\n",
       " 'subject': \"Re: Tomorrow's Meeting\",\n",
       " 'content': \"Hi [Boss's Name],\\n\\nI hope this message finds you well. I am writing to confirm my attendance at tomorrow's meeting. Please let me know if there are any specific topics or materials you would like me to prepare in advance.\\n\\nLooking forward to our discussion.\\n\\nBest regards,\\n\\n[Your Name]\"}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract tool calls and execute them\n",
    "args = output.tool_calls[0]['args']\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09f85694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email sent to boss@example.com with subject 'Re: Tomorrow's Meeting' and content: Hi [Boss's Name],\n",
      "\n",
      "I hope this message finds you well. I am writing to confirm my attendance at tomorrow's meeting. Please let me know if there are any specific topics or materials you would like me to prepare in advance.\n",
      "\n",
      "Looking forward to our discussion.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "# Call the tool\n",
    "result = write_email.invoke(args)\n",
    "print(result)  # \"Email to boss@company.com drafted with subject 'Re: Meeting Tomorrow'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f9c52a",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "[Agents](https://langchain-ai.github.io/langgraph/tutorials/workflows/) are systems where language models (LLMs) dynamically direct their own processes and tool usage. \n",
    "\n",
    "They are typically implemented as tool calling in a loop - the model decides which tool to use, calls it, and then uses the result to inform the next action. \n",
    "\n",
    "This is ideal for open-ended problems where it's difficult to predict the *exact* steps needed in advance.\n",
    "\n",
    "![agent-img](img/agent_loop.png)\n",
    "\n",
    "## Workflows\n",
    "\n",
    "When building LLM applications, agents are just one pattern to consider. \n",
    "\n",
    "Workflows are often appropriate when the control flow can easily be defined in advance. \n",
    "\n",
    "![workflow_v_agent](img/workflow_v_agent.png)\n",
    "\n",
    "## What is LangGraph? \n",
    "\n",
    "[LangGraph](https://langchain-ai.github.io/langgraph/concepts/high_level/) provides low-level supporting infrastructure that sits underneath *any* workflow or agent. It does not abstract prompts or architecture, and provides a few central benefits:\n",
    "\n",
    "- **Execution Control**:  Make it easy to define and combine agents and workflows.\n",
    "- **Persistence**: Provide a way to persist the state of a graph, which enables memory and human-in-the-loop.\n",
    "- **Deployment and Debugging**: Provide an easy onramp for testing, debugging, and deploying applications.\n",
    "\n",
    "### Execution Control\n",
    "\n",
    "LangGraph is an orchestration framework with [both declarative and imperative APIs](https://blog.langchain.dev/how-to-think-about-agent-frameworks/?utm_source=substack&utm_medium=email).\n",
    "\n",
    "**Declarative Programming** in LangGraph means:\n",
    "- Defining the overall structure of your application as a graph\n",
    "- Specifying what should happen rather than how it happens\n",
    "- Describing relationships between components through edges and conditions\n",
    "- Focusing on the \"what\" by describing the desired state and transitions\n",
    "\n",
    "Graphs in LangGraph use the [`StateGraph` class](https://langchain-ai.github.io/langgraph/concepts/low_level/#graphs) to define the overall structure of the application. In addition, LangGraph allows you to define a [`State` object](https://langchain-ai.github.io/langgraph/concepts/low_level/#state) that defines a schema for any information you want to track over the course of the application. This can be any object with `getattr()` in python, such as a dictionary, dataclass, or Pydantic object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3319290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class StateSchema(TypedDict):\n",
    "    request: str\n",
    "    email: str\n",
    "\n",
    "workflow = StateGraph(StateSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84bedb9",
   "metadata": {},
   "source": [
    "**Imperative Programming** in LangGraph means:\n",
    "- The actual implementation of each node's functionality\n",
    "- Writing code that defines exactly how each process works step-by-step\n",
    "- Having full control over the logic inside each node\n",
    "- Focusing on the \"how\" with detailed instructions\n",
    "\n",
    "![nodes_edges](img/nodes_edges.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5e79c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_email_node(state: StateSchema) -> StateSchema:\n",
    "    # Imperative code that processes the request\n",
    "    output = model_with_tools.invoke(state[\"request\"])\n",
    "    args = output.tool_calls[0]['args']\n",
    "    email = write_email.invoke(args)\n",
    "    return {\"email\": email}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737c8040",
   "metadata": {},
   "source": [
    "This dual approach gives LangGraph its flexibility - you declaratively define the overall structure while maintaining imperative control within each component, providing both high-level orchestration and fine-grained control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cc79b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'request': \"Draft a response to my boss about tomorrow's meeting\",\n",
       " 'email': \"Email sent to boss@example.com with subject 'Re: Tomorrow's Meeting' and content: Hi [Boss's Name],\\n\\nI hope this message finds you well. I am writing to confirm my attendance at tomorrow's meeting. Please let me know if there are any specific topics or materials you would like me to prepare in advance.\\n\\nLooking forward to our discussion.\\n\\nBest regards,\\n\\n[Your Name]\"}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_node(\"write_email_node\", write_email_node)\n",
    "workflow.add_edge(START, \"write_email_node\")\n",
    "workflow.add_edge(\"write_email_node\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "app.invoke({\"request\": \"Draft a response to my boss about tomorrow's meeting\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2446dea9",
   "metadata": {},
   "source": [
    "Routing between nodes can be done [conditionally](https://langchain-ai.github.io/langgraph/concepts/low_level/#conditional-edges) using a simple function. \n",
    "\n",
    "The return value of this function is used as the name of the node (or list of nodes) to send the state to next. \n",
    "\n",
    "You can optionally provide a dictionary that maps the routing_function's output to the name of the next node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f29b05bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "def call_llm(state: MessagesState) -> MessagesState:\n",
    "    \"\"\"Run LLM\"\"\"\n",
    "\n",
    "    output = model_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [output]}\n",
    "\n",
    "def run_tool(state: dict):\n",
    "    \"\"\"Performs the tool call\"\"\"\n",
    "\n",
    "    result = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        observation = write_email.invoke(tool_call[\"args\"])\n",
    "        result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": tool_call[\"id\"]})\n",
    "    return {\"messages\": result}\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"run_tool\", END]:\n",
    "    \"\"\"Route to tool handler, or end if Done tool called\"\"\"\n",
    "    \n",
    "    # Get the last message\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # If the last message is a tool call, check if it's a Done tool call\n",
    "    if last_message.tool_calls:\n",
    "        return \"run_tool\"\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"call_llm\", call_llm)\n",
    "workflow.add_node(\"run_tool\", run_tool)\n",
    "workflow.add_edge(START, \"call_llm\")\n",
    "workflow.add_conditional_edges(\"call_llm\", should_continue, {\"run_tool\": \"run_tool\", END: END})\n",
    "workflow.add_edge(\"run_tool\", END)\n",
    "\n",
    "# Run the workflow\n",
    "app = workflow.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dadbafde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"Draft a response to my boss about tomorrow's meeting\", additional_kwargs={}, response_metadata={}, id='5e2d9fe3-c075-47ba-a253-f06ffb67aab5'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_iIS382COCMtqYtfwIfBBf8P9', 'function': {'arguments': '{\"to\":\"boss@example.com\",\"subject\":\"Re: Tomorrow\\'s Meeting\",\"content\":\"Hi [Boss\\'s Name],\\\\n\\\\nI hope this message finds you well. I am writing to confirm my attendance at tomorrow\\'s meeting. Please let me know if there are any specific topics or materials you would like me to prepare in advance.\\\\n\\\\nLooking forward to our discussion.\\\\n\\\\nBest regards,\\\\n\\\\n[Your Name]\"}', 'name': 'write_email'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 61, 'total_tokens': 158, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_90122d973c', 'id': 'chatcmpl-BTwquc2LNqLegxeH93d9gDyD3tRcf', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ded32fbe-2094-4a9d-93ca-8e3bd79b35f0-0', tool_calls=[{'name': 'write_email', 'args': {'to': 'boss@example.com', 'subject': \"Re: Tomorrow's Meeting\", 'content': \"Hi [Boss's Name],\\n\\nI hope this message finds you well. I am writing to confirm my attendance at tomorrow's meeting. Please let me know if there are any specific topics or materials you would like me to prepare in advance.\\n\\nLooking forward to our discussion.\\n\\nBest regards,\\n\\n[Your Name]\"}, 'id': 'call_iIS382COCMtqYtfwIfBBf8P9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 61, 'output_tokens': 97, 'total_tokens': 158, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content=\"Email sent to boss@example.com with subject 'Re: Tomorrow's Meeting' and content: Hi [Boss's Name],\\n\\nI hope this message finds you well. I am writing to confirm my attendance at tomorrow's meeting. Please let me know if there are any specific topics or materials you would like me to prepare in advance.\\n\\nLooking forward to our discussion.\\n\\nBest regards,\\n\\n[Your Name]\", id='d77958ea-98d9-40fb-8771-c91924a81bdc', tool_call_id='call_iIS382COCMtqYtfwIfBBf8P9')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = app.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Draft a response to my boss about tomorrow's meeting\"}]})\n",
    "result[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6e506f",
   "metadata": {},
   "source": [
    "### Persistence\n",
    "\n",
    "It can be very useful to the pause the graph during execution. As we'll see later, this enables interaction like human-in-the-loop. LangGraph has a built-in persistence layer, implemented through checkpointers. When you compile graph with a checkpointer, the checkpointer saves a [checkpoints](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpoints) of the graph state at every super-step. Those checkpoints are saved to a thread, which can be accessed after graph execution. Using checkpoints is simple - you only need to specify a `thread_id` when invoking a graph, and LangGraph handles the persistence automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a72377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "app = workflow.compile(checkpointer=InMemorySaver())\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "result = app.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Draft a response to my boss about tomorrow's meeting\"}]}, config)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10984007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content=\"Draft a response to my boss about tomorrow's meeting\", additional_kwargs={}, response_metadata={}, id='8545648c-aaf3-4973-a9c1-9eebb67a5373'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_JiUJeMikwtibD6AeDVtFas0p', 'function': {'arguments': '{\"to\":\"boss@example.com\",\"subject\":\"Re: Tomorrow\\'s Meeting\",\"content\":\"Hi [Boss\\'s Name],\\\\n\\\\nI hope this message finds you well. I am writing to confirm my attendance at tomorrow\\'s meeting. Please let me know if there are any specific topics or materials you would like me to prepare in advance.\\\\n\\\\nLooking forward to our discussion.\\\\n\\\\nBest regards,\\\\n\\\\n[Your Name]\"}', 'name': 'write_email'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 61, 'total_tokens': 158, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_90122d973c', 'id': 'chatcmpl-BTx0GcTJU9kiTVSuj3o6qvwpreG6p', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b05a308b-d851-45a9-a991-65dc59a4d82b-0', tool_calls=[{'name': 'write_email', 'args': {'to': 'boss@example.com', 'subject': \"Re: Tomorrow's Meeting\", 'content': \"Hi [Boss's Name],\\n\\nI hope this message finds you well. I am writing to confirm my attendance at tomorrow's meeting. Please let me know if there are any specific topics or materials you would like me to prepare in advance.\\n\\nLooking forward to our discussion.\\n\\nBest regards,\\n\\n[Your Name]\"}, 'id': 'call_JiUJeMikwtibD6AeDVtFas0p', 'type': 'tool_call'}], usage_metadata={'input_tokens': 61, 'output_tokens': 97, 'total_tokens': 158, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"Email sent to boss@example.com with subject 'Re: Tomorrow's Meeting' and content: Hi [Boss's Name],\\n\\nI hope this message finds you well. I am writing to confirm my attendance at tomorrow's meeting. Please let me know if there are any specific topics or materials you would like me to prepare in advance.\\n\\nLooking forward to our discussion.\\n\\nBest regards,\\n\\n[Your Name]\", id='ee787204-657c-445c-ad59-0d2e806a42a2', tool_call_id='call_JiUJeMikwtibD6AeDVtFas0p')]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f029f21-8e77-632e-8002-5cce1ab6e6c6'}}, metadata={'source': 'loop', 'writes': {'run_tool': {'messages': [{'role': 'tool', 'content': \"Email sent to boss@example.com with subject 'Re: Tomorrow's Meeting' and content: Hi [Boss's Name],\\n\\nI hope this message finds you well. I am writing to confirm my attendance at tomorrow's meeting. Please let me know if there are any specific topics or materials you would like me to prepare in advance.\\n\\nLooking forward to our discussion.\\n\\nBest regards,\\n\\n[Your Name]\", 'tool_call_id': 'call_JiUJeMikwtibD6AeDVtFas0p'}]}}, 'step': 2, 'parents': {}, 'thread_id': '1'}, created_at='2025-05-05T20:47:02.513122+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f029f21-8e6f-63c2-8001-5bac106f04e9'}}, tasks=())"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the latest state snapshot\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "app.get_state(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8639a518",
   "metadata": {},
   "source": [
    "### Deployment and Debugging\n",
    "\n",
    "When we are using LangChain or LangGraph, LangSmith logging [will work out of the box](https://docs.smith.langchain.com/observability/how_to_guides/trace_with_langgraph) with the following environment variables set:\n",
    "\n",
    "```\n",
    "export LANGSMITH_TRACING=true\n",
    "export LANGSMITH_API_KEY=\"<your-langsmith-api-key>\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f864ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"LANGSMITH_TRACING\")\n",
    "_set_env(\"LANGSMITH_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0269214",
   "metadata": {},
   "source": [
    "Trace from above graph execution:\n",
    "\n",
    "https://smith.langchain.com/public/6e5d8983-e88c-490b-a087-91a94765d7c2/r\n",
    "\n",
    "When you've built a graph, it's easy to deploy using [LangGraph Platform](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/). A deployment hosts with the graph with an API [server](https://langchain-ai.github.io/langgraph/concepts/langgraph_server/) and offers an interactive IDE (LangGraph [Studio](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/)).\n",
    "\n",
    "We can start a deployment locally using `langgraph dev`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf38d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "! langgraph dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3644093",
   "metadata": {},
   "source": [
    "Here we can see a visualization of the graph as well as the graph state in Studio.\n",
    "\n",
    "![langgraph_studio](img/langgraph_studio.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226a3f4a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
