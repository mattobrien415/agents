{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bb66df4",
   "metadata": {},
   "source": [
    "# Self-Improving Email Assistant\n",
    "\n",
    "AI agents promise to transform how we work, but there's often a gap between hype and reality: to truly act on our behalf, agents need to learn and remember our preferences for personalization. In this repo, we're going to show how to build self-improving and personalized agents from scratch using LangChain, LangGraph, and LangSmith. \n",
    " \n",
    "We're going to build an agent that can act an an e-mail assistant, because this is often a rather tedious task that could benefit from an AI assistant, but it requires a high level of personalization (e.g., what to respond to, what to ignore, what to schedule a meeting for, and how to respond). \n",
    "\n",
    "Below is an overview of the email assistant we'll build with 1) the agent architecture (LangGraph), 2) testing (LangSmith), 3) human-in-the-loop (Agent Inbox), and 4) memory (LangMem). The notebooks are organized in the order of the steps, so you can follow along and accompanying completed code is in the `src/email_assistant` directory.\n",
    "\n",
    "![overview-img](img/overview.png)\n",
    "\n",
    "## What are Agents?\n",
    "\n",
    "[Agents](https://langchain-ai.github.io/langgraph/tutorials/workflows/) are systems where language models (LLMs) dynamically direct their own processes and tool usage. Unlike workflows with predefined paths, agents can make decisions about which actions to take based on their understanding of a task. Agents are particularly valuable for open-ended problems like email management, where it's difficult to predict the *exact* steps needed in advance: some emails can be responded to directly and some need coordination with tools (e.g, scheduling a meeting).\n",
    "\n",
    "![agent-img](img/agent.png)\n",
    "\n",
    "### Tool Definition\n",
    "\n",
    " As you will see, agents are typically implemented [using tool calling in a loop](https://python.langchain.com/docs/concepts/tool_calling/). Tools let agents interact with their environment. In LangChain/Graph, tools are easy to define: we can just use Python functions with the [@tool decorator](https://python.langchain.com/docs/concepts/tools/) or [MCP servers](https://github.com/langchain-ai/langchain-mcp-adapters). Let's start by defining some simple tools that an email assistant will use with the `@tool` decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b708ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def write_email(to: str, subject: str, content: str) -> str:\n",
    "    \"\"\"Write and send an email.\"\"\"\n",
    "    # Placeholder response - in real app would send email\n",
    "    return f\"Email sent to {to} with subject '{subject}'\"\n",
    "\n",
    "@tool\n",
    "def schedule_meeting(\n",
    "    attendees: list[str], subject: str, duration_minutes: int, preferred_day: str\n",
    ") -> str:\n",
    "    \"\"\"Schedule a calendar meeting.\"\"\"\n",
    "    # Placeholder response - in real app would check calendar and schedule\n",
    "    return f\"Meeting '{subject}' scheduled for {preferred_day} with {len(attendees)} attendees\"\n",
    "\n",
    "@tool\n",
    "def check_calendar_availability(day: str) -> str:\n",
    "    \"\"\"Check calendar availability for a given day.\"\"\"\n",
    "    # Placeholder response - in real app would check actual calendar\n",
    "    return f\"Available times on {day}: 9:00 AM, 2:00 PM, 4:00 PM\"\n",
    "\n",
    "@tool\n",
    "def triage_email(category: Literal[\"ignore\", \"notify\", \"respond\"]) -> str:\n",
    "    \"\"\"Triage an email into one of three categories: ignore, notify, respond.\"\"\"\n",
    "    return f\"Classification Decision: {category}\"\n",
    "\n",
    "@tool\n",
    "class Done(BaseModel):\n",
    "      \"\"\"E-mail has been sent.\"\"\"\n",
    "      done: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b2600",
   "metadata": {},
   "source": [
    "### Augmenting the LLM with Tools\n",
    "\n",
    "Now we connect these tools to a LLM. We'll use LangChain's [`init_chat_model`](https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html#init-chat-model) interface, which allows us to initialize many different chat models. We [enforce tool use](https://python.langchain.com/docs/how_to/tool_choice/) by setting `tool_choice=\"required\"` and set the temperature to `0.0` to make the agent more deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f263cc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Collect all tools\n",
    "tools = [write_email, schedule_meeting, check_calendar_availability, triage_email, Done]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "# Initialize the LLM, enforcing tool use\n",
    "llm = init_chat_model(\"openai:gpt-4o\", tool_choice=\"required\", temperature=0.0)\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a469c7",
   "metadata": {},
   "source": [
    "## Agent Orchestration with LangGraph\n",
    "\n",
    "Now we have an LLM with tools; how can we orchestrate it as an agent? This is where LangGraph comes in. We can create an agent using LangGraph's [pre-built method](https://langchain-ai.github.io/langgraph/tutorials/workflows/#pre-built) by passing in the LLM, tools, and prompt. \n",
    "\n",
    "![overview-img](img/overview_agent.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfde427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from src.email_assistant.prompts import agent_system_prompt_baseline, default_background, default_response_preferences, default_cal_preferences, default_triage_instructions\n",
    "\n",
    "# Pass in:\n",
    "# (1) the LLM\n",
    "# (2) the tools list\n",
    "# (3) the prompt\n",
    "\n",
    "# Agent system prompt\n",
    "system_prompt = \"\"\"\n",
    "< Role >\n",
    "You are a top-notch executive assistant who cares about helping your executive perform as well as possible.\n",
    "</ Role >\n",
    "\n",
    "< Tools >\n",
    "You have access to the following tools to help manage communications and schedule:\n",
    "1. triage_email(ignore, notify, respond) - Triage emails into one of three categories\n",
    "2. write_email(to, subject, content) - Send emails to specified recipients\n",
    "3. schedule_meeting(attendees, subject, duration_minutes, preferred_day) - Schedule calendar meetings\n",
    "4. check_calendar_availability(day) - Check available time slots for a given day\n",
    "</ Tools >\n",
    "\n",
    "< Instructions >\n",
    "When handling emails, follow these steps:\n",
    "1. Carefully analyze the email content and purpose\n",
    "2. For responding to the email, draft a response email with the write_email tool\n",
    "3. For meeting requests, use the check_calendar_availability tool to find open time slots\n",
    "4. To schedule a meeting, use the the schedule_meeting tool \n",
    "5. If you scheduled a meeting, then draft a short response email using the write_email tool\n",
    "6. After using the write_email tool, the task is complete \n",
    "</ Instructions >\n",
    "\n",
    "< Triage Instructions >\n",
    "Emails that are not worth responding to:\n",
    "- Marketing newsletters and promotional emails and spam\n",
    "\n",
    "There are also other things that should be known about, but don't require an email response. For these, you should notify (using the `notify` response). Examples of this include:\n",
    "- Team member out sick or on vacation\n",
    "\n",
    "Emails that are worth responding to:\n",
    "- System Admin notifications (use a brief thank you for the email)\n",
    "- Direct questions from team members requiring expertise\n",
    "- Meeting requests requiring confirmation\n",
    "</ Triage Instructions >\n",
    "\"\"\"\n",
    "\n",
    "# Create the agent\n",
    "pre_built_agent = create_react_agent(model=init_chat_model(\"openai:gpt-4o\", temperature=0.0), \n",
    "                                     tools=[write_email, schedule_meeting, check_calendar_availability, triage_email], \n",
    "                                     prompt=system_prompt)\n",
    "\n",
    "# Email input\n",
    "email_input = {\n",
    "    \"author\": \"System Admin <sysadmin@company.com>\",\n",
    "    \"to\": \"Development Team <dev@company.com>\",\n",
    "    \"subject\": \"Scheduled maintenance - database downtime\",\n",
    "    \"email_thread\": \"Hi team,\\n\\nThis is a reminder that we'll be performing scheduled maintenance on the production database tonight from 2AM to 4AM EST. During this time, all database services will be unavailable.\\n\\nPlease plan your work accordingly and ensure no critical deployments are scheduled during this window.\\n\\nThanks,\\nSystem Admin Team\"\n",
    "}\n",
    "\n",
    "# Run the agent\n",
    "messages = [{\"role\": \"user\", \"content\": str(email_input)}]\n",
    "response = pre_built_agent.invoke({\"messages\": messages})\n",
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afffd02b",
   "metadata": {},
   "source": [
    "We mentioned that agents typically use tool calling in a loop. [ReAct](https://arxiv.org/abs/2210.03629) is an architecture that implements this, using a loop of reasoning and tool calling that only exits when the LLM decides to no longer call any tools. To understand what happens under the hood when we using the `create_react_agent` pre-built method, below we'll break down the components of the agent in detail. \n",
    "\n",
    "### Agent State\n",
    "\n",
    "When building an agent, it's important to consider the information that you want to track over time. LangGraph allows you to define a [`State` object](https://langchain-ai.github.io/langgraph/concepts/low_level/#state) that defines a schema for this information. It can be any object with `getattr()` in python, such as a dictionary, dataclass, or Pydantic object. \n",
    " \n",
    "Because it's so common to track a list of [messages](https://python.langchain.com/docs/concepts/messages/#), LangGraph provides a [`MessagesState` object](https://langchain-ai.github.io/langgraph/concepts/low_level/#messagesstate) that is a just dictionary with a `messages` key. However, LangGraph gives you flexibility to track other information. As an example, we can define a custom `State` object that extends `MessagesState` and adds a `classification_decision` key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71881366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class State(MessagesState):\n",
    "    # This state class has the messages key build in\n",
    "    classification_decision: Literal[\"ignore\", \"respond\", \"notify\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272d8715",
   "metadata": {},
   "source": [
    "This means that our graph has two keys in the state: `messages` and `classification_decision`. \n",
    "\n",
    "### Agent nodes\n",
    "\n",
    "Under the hood of `pre_built_agent`, LangGraph uses a [`StateGraph`](https://langchain-ai.github.io/langgraph/concepts/low_level/#stategraph) that defines the flow of information and decision-making in your agent through nodes, edges, and conditional routing. \n",
    "\n",
    "- **Nodes**: Functions that process state\n",
    "- **Edges**: Connections that define how state flows between nodes\n",
    "- **Conditional routing**: Dynamic decision-making\n",
    "\n",
    "In the case of an agent this is straightforward: \n",
    "\n",
    "- **Nodes**: Perform the LLM decision-making and tool calling\n",
    "- **Edges**: LLM decision-making and tool calling nodes are connected\n",
    "- **Conditional routing**: Route from LLM decision to tool calling if a tool is called\n",
    "\n",
    "#### LLM Decision-making node\n",
    "\n",
    "Here, we define the LLM decision-making node. This node takes in the current state, calls the LLM, and updates `messages` with the LLM output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5d448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2c120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.email_assistant.prompts import agent_system_prompt_baseline, default_background, default_response_preferences, default_cal_preferences, default_triage_instructions\n",
    "\n",
    "def llm_call(state: State):\n",
    "    \"\"\"LLM decides whether to call a tool or not\"\"\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            # Invoke the LLM\n",
    "            llm_with_tools.invoke(\n",
    "                # Add the system prompt\n",
    "                [   \n",
    "                    {\"role\": \"system\", \"content\": agent_system_prompt_baseline.format(\n",
    "                        background=default_background,\n",
    "                        response_preferences=default_response_preferences,\n",
    "                        cal_preferences=default_cal_preferences, \n",
    "                        triage_instructions=default_triage_instructions\n",
    "                    )}\n",
    "                ]\n",
    "                # Add the current messages to the prompt\n",
    "                + state[\"messages\"]\n",
    "            )\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f05d11a",
   "metadata": {},
   "source": [
    "We return a dictionary to update the state. Each of our state keys handles updates individually. By default an update will *overwrite* the existing state key. However, you can [define custom update logic](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers). For example, `messages` key in the built-in `MessagesState` appends new messages to the list. \n",
    "\n",
    "#### Handling Tool Calls\n",
    "\n",
    "After the LLM makes a decision, we need to execute the chosen tool. The `tool_handler` node executes the tool. We can see that nodes can update the graph state to capture any important state changes, such as the classification decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eb6dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_handler(state: State):\n",
    "    \"\"\"Process tool calls and execute them\"\"\"\n",
    "    \n",
    "    # Store messages\n",
    "    result = []\n",
    "    # Track if we need to update classification_decision\n",
    "    classification_decision = None\n",
    "    \n",
    "    # Iterate over the tool calls in the last message\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        # Execute the tool\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        # Log the classification decision if triage_email was called\n",
    "        if tool_call[\"name\"] == \"triage_email\":\n",
    "            # Get the classification decision from the tool call\n",
    "            classification_decision = tool_call[\"args\"][\"category\"]\n",
    "        # Add the tool response\n",
    "        result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": tool_call[\"id\"]})\n",
    "    \n",
    "    # Return updated state \n",
    "    if classification_decision:\n",
    "        return {\n",
    "            # Append the tool result to the messages\n",
    "            \"messages\": result,\n",
    "            # Update the classification decision\n",
    "            \"classification_decision\": classification_decision\n",
    "        }\n",
    "    else:\n",
    "        # If no tool was called, append the tool result to the messages\n",
    "        return {\"messages\": result}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4721dede",
   "metadata": {},
   "source": [
    "### Agent Conditional Routing\n",
    "\n",
    "Our agent needs to decide when to continue using tools and when to stop. This conditional routing function directs the agent to either continue or terminate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7cbea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "def should_continue(state: State) -> Literal[\"tool_handler\", END]:\n",
    "    \"\"\"Route to tool handler, or end if Done tool called\"\"\"\n",
    "    # Get the last message\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If the last message is a tool call, check if it's a Done tool call\n",
    "    if last_message.tool_calls:\n",
    "        for tool_call in last_message.tool_calls: \n",
    "            if tool_call[\"name\"] == \"Done\":\n",
    "                return END\n",
    "            else:\n",
    "                return \"tool_handler\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb4ede8",
   "metadata": {},
   "source": [
    "### Agent Graph\n",
    "\n",
    "Finally, we can assemble all components into a LangGraph state graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81df767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Build workflow\n",
    "overall_workflow = StateGraph(State, input=MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "overall_workflow.add_node(\"llm_call\", llm_call)\n",
    "overall_workflow.add_node(\"tool_handler\", tool_handler)\n",
    "\n",
    "# Add edges\n",
    "overall_workflow.add_edge(START, \"llm_call\")\n",
    "overall_workflow.add_conditional_edges(\n",
    "    \"llm_call\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tool_handler\": \"tool_handler\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "overall_workflow.add_edge(\"tool_handler\", \"llm_call\")\n",
    "\n",
    "# Compile the agent\n",
    "agent = overall_workflow.compile()\n",
    "\n",
    "# View\n",
    "from IPython.display import Image, display\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8367c4",
   "metadata": {},
   "source": [
    "This creates a graph that:\n",
    "1. Starts with an LLM decision\n",
    "2. Conditionally routes to tool execution or termination\n",
    "3. After tool execution, returns to LLM for the next decision\n",
    "4. Repeats until completion or no tool is called\n",
    "\n",
    "We can run the agent with a simple email input. The compiled agent has an interface with [various useful methods](https://python.langchain.com/docs/concepts/runnables/), including `invoke()`, which takes in a `state` dictionary and returns the final state. However, as we'll see later, we can also stream the agent's execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e06917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Email input\n",
    "email_input = {\n",
    "    \"author\": \"System Admin <sysadmin@company.com>\",\n",
    "    \"to\": \"Development Team <dev@company.com>\",\n",
    "    \"subject\": \"Scheduled maintenance - database downtime\",\n",
    "    \"email_thread\": \"Hi team,\\n\\nThis is a reminder that we'll be performing scheduled maintenance on the production database tonight from 2AM to 4AM EST. During this time, all database services will be unavailable.\\n\\nPlease plan your work accordingly and ensure no critical deployments are scheduled during this window.\\n\\nThanks,\\nSystem Admin Team\"\n",
    "}\n",
    "\n",
    "# Invoke the agent\n",
    "messages = [{\"role\": \"user\", \"content\": str(email_input)}]\n",
    "response = agent.invoke({\"messages\": messages})\n",
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da36f1fa",
   "metadata": {},
   "source": [
    "## Information Flow\n",
    "\n",
    "The complete flow of our email assistant agent:\n",
    "\n",
    "1. An email arrives and is passed to the agent as a message\n",
    "2. The LLM analyzes the email and decides which tool to use\n",
    "3. If the LLM calls the `triage_email` tool, the classification is stored\n",
    "4. The agent continues reasoning and acting until it calls `Done`\n",
    "5. The final state includes the messages and any classification decision\n",
    "\n",
    "This implementation demonstrates a tool calling agent that alternates between reasoning (LLM decisions) and acting (tool execution) to accomplish complex tasks.\n",
    "\n",
    "## Workflows vs. Agents\n",
    "\n",
    "We can see that it's easy to build an agent using LangGraph. But, what if we want to add more tools? You'll notice that the agent's prompt and scope of control grows as the number of tools / decisions it oversees increases. When we think about our application, we *always* want to triage incoming emails. So, we know that the first step is always going to be a triage step. Why not set up our application so that the first step is always the triage step? This is the motivation for the concept of a [workflow](https://langchain-ai.github.io/langgraph/how-tos/workflows/)!  \n",
    "\n",
    "### Workflows\n",
    "- Have predefined code paths and decision logic\n",
    "- LLMs are components used for specific tasks\n",
    "- Best for structured problems with clear procedures, but not open-ended\n",
    "- Predictable behavior with explicit control flow\n",
    "\n",
    "### Agents\n",
    "- LLMs drive the decision-making process\n",
    "- Dynamically choose which tools to use\n",
    "- Best for open-ended problems where we can't enumerate the steps  \n",
    "- More flexible but potentially less reliable\n",
    "\n",
    "![agent_workflow_img](img/agent_workflow.png)\n",
    "\n",
    "### Combing the two\n",
    "We can use LangGraph to build a routing step prior to the agent, which handles the triage decision. This has some benefits, including separation of concerns. The triage router only focuses on the triage decision, while the agent focuses *only* on the response. As we'll see, this *separation of concerns* is useful because we'll add more tools to our agent. Breaking out the triage decision frees up some \"cognitive resources\" for the agent to focus only on the response. \n",
    "\n",
    "### The Triage Router\n",
    "\n",
    "Our email assistant implementation uses a router pattern. The router analyzes the email and makes a critical decision: should we respond, notify, or ignore? Based on this decision, it directs the flow either to the response agent or directly to the end state. We use [Command](https://langchain-ai.github.io/langgraph/how-tos/command/) objects in LangGraph to both update the state and select the next node to visit.\n",
    "\n",
    "![router-img](img/router.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bc2db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from email_assistant.schemas import RouterSchema\n",
    "from email_assistant.utils import parse_email, format_email_markdown\n",
    "from email_assistant.prompts import triage_system_prompt, triage_user_prompt\n",
    "\n",
    "from langgraph.types import Command\n",
    "\n",
    "# Initialize the LLM for use with router / structured output\n",
    "llm = init_chat_model(\"openai:gpt-4o\", temperature=0.0)\n",
    "llm_router = llm.with_structured_output(RouterSchema) \n",
    "\n",
    "class State(MessagesState):\n",
    "    # We can add a specific key to our state for the email input\n",
    "    email_input: dict\n",
    "    classification_decision: Literal[\"ignore\", \"respond\", \"notify\"]\n",
    "\n",
    "def triage_router(state: State) -> Command[Literal[\"response_agent\", \"__end__\"]]:\n",
    "    \"\"\"Analyze email content to decide if we should respond, notify, or ignore.\n",
    "\n",
    "    The triage step prevents the assistant from wasting time on:\n",
    "    - Marketing emails and spam\n",
    "    - Company-wide announcements\n",
    "    - Messages meant for other teams\n",
    "    \"\"\"\n",
    "    author, to, subject, email_thread = parse_email(state[\"email_input\"])\n",
    "    system_prompt = triage_system_prompt.format(\n",
    "        background=default_background,\n",
    "        triage_instructions=default_triage_instructions\n",
    "    )\n",
    "\n",
    "    user_prompt = triage_user_prompt.format(\n",
    "        author=author, to=to, subject=subject, email_thread=email_thread\n",
    "    )\n",
    "\n",
    "    result = llm_router.invoke(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "    )\n",
    "    if result.classification == \"respond\":\n",
    "        print(\"📧 Classification: RESPOND - This email requires a response\")\n",
    "        goto = \"response_agent\"\n",
    "        update = {\n",
    "            \"messages\": [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"E-mail classification Decision: {result.classification} is done.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Respond to the email: \\n\\n{format_email_markdown(subject, author, to, email_thread)}\",\n",
    "                }\n",
    "            ],\n",
    "            \"classification_decision\": result.classification,\n",
    "        }\n",
    "    elif result.classification == \"ignore\":\n",
    "        print(\"🚫 Classification: IGNORE - This email can be safely ignored\")\n",
    "        update =  {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"E-mail classification Decision: {result.classification} is done.\"\n",
    "                }\n",
    "            ],\n",
    "            \"classification_decision\": result.classification,\n",
    "        }\n",
    "        goto = END\n",
    "    elif result.classification == \"notify\":\n",
    "        # If real life, this would do something else\n",
    "        print(\"🔔 Classification: NOTIFY - This email contains important information\")\n",
    "        update = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"E-mail classification Decision: {result.classification} is done.\"\n",
    "                }\n",
    "            ],\n",
    "            \"classification_decision\": result.classification,\n",
    "        }\n",
    "        goto = END\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid classification: {result.classification}\")\n",
    "    return Command(goto=goto, update=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf9588a",
   "metadata": {},
   "source": [
    "### Building the Workflow with a Router\n",
    "\n",
    "With the router pattern, our overall workflow becomes a composition of components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b35d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    # This state class has the messages key build in\n",
    "    email_input: dict\n",
    "    classification_decision: Literal[\"ignore\", \"respond\", \"notify\"]\n",
    "\n",
    "overall_workflow = (\n",
    "    StateGraph(State)\n",
    "    .add_node(triage_router)\n",
    "    .add_node(\"response_agent\", agent)\n",
    "    .add_edge(START, \"triage_router\")\n",
    ").compile()\n",
    "\n",
    "# View\n",
    "from IPython.display import Image, display\n",
    "display(Image(overall_workflow.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2091d5cc",
   "metadata": {},
   "source": [
    "This is a higher-level composition where:\n",
    "1. First, the triage router analyzes the email\n",
    "2. If needed, the response agent handles crafting a response\n",
    "3. The workflow ends when either the triage decides no response is needed or the response agent completes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f18a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the agent\n",
    "response = overall_workflow.invoke({\"email_input\": email_input})\n",
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f631f61f",
   "metadata": {},
   "source": [
    "## Testing with Local Deployment\n",
    "\n",
    "You can find files for these in the `src/email_assistant` directory:\n",
    "\n",
    "* `src/email_assistant/baseline_agent.py` \n",
    "* `src/email_assistant/email_assistant.py`\n",
    "\n",
    "You can test them locally in LangGraph Studio by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5586a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "! langgraph dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12752016",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Example e-mail you can test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ee005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_input = {\n",
    "  \"author\": \"Alice Smith <alice.smith@company.com>\",\n",
    "  \"to\": \"John Doe <john.doe@company.com>\",\n",
    "  \"subject\": \"Quick question about API documentation\",\n",
    "  \"email_thread\": \"Hi John,\\nI was reviewing the API documentation for the new authentication service and noticed a few endpoints seem to be missing from the specs. Could you help clarify if this was intentional or if we should update the docs?\\nSpecifically, I'm looking at:\\n- /auth/refresh\\n- /auth/validate\\nThanks!\\nAlice\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09e33b6",
   "metadata": {},
   "source": [
    "![studio-img](img/studio.png)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
