{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc082433",
   "metadata": {},
   "source": [
    "# LangGraph 101\n",
    "\n",
    "[LLMs](https://python.langchain.com/docs/concepts/chat_models/) make it possible to embed intelligence into a new class of applications. [LangGraph](https://langchain-ai.github.io/langgraph/) is a framework to help build applications with LLMs. Here, we will overview the basics of LangGraph, explain its benefits, show how to use it to build workflows / agents, and show how it works with [LangChain](https://www.langchain.com/) / [LangSmith](https://docs.smith.langchain.com/).\n",
    "\n",
    "![ecosystem](img/ecosystem.png)\n",
    "\n",
    "## Chat models\n",
    "\n",
    "[Chat models](https://python.langchain.com/docs/concepts/chat_models/) are the foundation of LLM applications. They are typically accessed through a chat interface that takes a list of messages as input and returns a message as output. LangChain provides [a standardized interface for chat models](https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html), making it easy to [access many different providers](https://python.langchain.com/docs/integrations/chat/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cecc2b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0ee8f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"openai:gpt-4.1\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50777b0b",
   "metadata": {},
   "source": [
    "## Running the model\n",
    "\n",
    "The `init_chat_model` interface provides [standardized](https://python.langchain.com/docs/concepts/runnables/) methods for using chat models, which include:\n",
    "- `invoke()`: Synchronously process inputs and return outputs\n",
    "- `stream()`: Return outputs [incrementally](https://python.langchain.com/docs/concepts/streaming/#stream-and-astream) as they're generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a28159d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(\"What is LangGraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41137023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc1d00eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**LangGraph** is an open-source framework designed for building stateful, multi-agent applications powered by Large Language Models (LLMs). It extends the popular [LangChain](https://www.langchain.com/) ecosystem, focusing on enabling complex workflows where multiple agents (LLMs, tools, or humans) interact in a graph-like structure.\\n\\n### Key Features\\n\\n- **Graph-based Workflows:**  \\n  LangGraph lets you define workflows as graphs, where each node can be an agent, a tool, or a function, and edges represent possible transitions based on state or output.\\n- **Stateful Interactions:**  \\n  Unlike simple chains, LangGraph maintains and updates a shared state as the workflow progresses, allowing for memory, context, and iterative reasoning.\\n- **Multi-Agent Collaboration:**  \\n  Easily orchestrate multiple agents that can communicate, collaborate, or debate to solve complex tasks.\\n- **Flexible Control Flow:**  \\n  Supports loops, branching, and conditional logic, making it suitable for advanced applications like multi-turn conversations, document analysis, or collaborative problem-solving.\\n\\n### Typical Use Cases\\n\\n- **Conversational AI:** Multi-turn, context-aware chatbots or assistants.\\n- **Agentic Workflows:** Agents that plan, execute, and reflect on tasks, possibly using tools or APIs.\\n- **Collaborative Agents:** Multiple LLMs (or LLM+human) working together, e.g., for code review, research, or negotiation.\\n\\n### Example\\n\\nA simple LangGraph workflow might look like:\\n- User input → Agent 1 (Planner) → Agent 2 (Executor) → Tool → Output\\n\\n### Resources\\n\\n- **GitHub:** [LangGraph repository](https://github.com/langchain-ai/langgraph)\\n- **Docs:** [LangGraph documentation](https://langchain-ai.github.io/langgraph/)\\n- **Announcement:** [LangChain blog post](https://blog.langchain.dev/introducing-langgraph/)\\n\\n---\\n\\n**In summary:**  \\nLangGraph is a framework for building advanced, stateful, multi-agent LLM applications using graph-based workflows, enabling more complex and interactive AI systems than simple chains or pipelines.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 432, 'prompt_tokens': 12, 'total_tokens': 444, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_cf18407276', 'id': 'chatcmpl-BTwK4OamVymNKUy4QaWpwmAFL3259', 'finish_reason': 'stop', 'logprobs': None}, id='run-3fd9d1ef-4a0a-4bed-bcbb-b97bd7737568-0', usage_metadata={'input_tokens': 12, 'output_tokens': 432, 'total_tokens': 444, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7bc6518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**LangGraph** is an open-source framework designed for building stateful, multi-agent applications powered by Large Language Models (LLMs). It extends the popular [LangChain](https://www.langchain.com/) ecosystem, focusing on enabling complex workflows where multiple agents (LLMs, tools, or humans) interact in a graph-like structure.\\n\\n### Key Features\\n\\n- **Graph-based Workflows:**  \\n  LangGraph lets you define workflows as graphs, where each node can be an agent, a tool, or a function, and edges represent possible transitions based on state or output.\\n- **Stateful Interactions:**  \\n  Unlike simple chains, LangGraph maintains and updates a shared state as the workflow progresses, allowing for memory, context, and iterative reasoning.\\n- **Multi-Agent Collaboration:**  \\n  Easily orchestrate multiple agents that can communicate, collaborate, or debate to solve complex tasks.\\n- **Flexible Control Flow:**  \\n  Supports loops, branching, and conditional logic, making it suitable for advanced applications like multi-turn conversations, document analysis, or collaborative problem-solving.\\n\\n### Typical Use Cases\\n\\n- **Conversational AI:** Multi-turn, context-aware chatbots or assistants.\\n- **Agentic Workflows:** Agents that plan, execute, and reflect on tasks, possibly using tools or APIs.\\n- **Collaborative Agents:** Multiple LLMs (or LLM+human) working together, e.g., for code review, research, or negotiation.\\n\\n### Example\\n\\nA simple LangGraph workflow might look like:\\n- User input → Agent 1 (Planner) → Agent 2 (Executor) → Tool → Output\\n\\n### Resources\\n\\n- **GitHub:** [LangGraph repository](https://github.com/langchain-ai/langgraph)\\n- **Docs:** [LangGraph documentation](https://langchain-ai.github.io/langgraph/)\\n- **Announcement:** [LangChain blog post](https://blog.langchain.dev/introducing-langgraph/)\\n\\n---\\n\\n**In summary:**  \\nLangGraph is a framework for building advanced, stateful, multi-agent LLM applications using graph-based workflows, enabling more complex and interactive AI systems than simple chains or pipelines.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a24d8ef",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "[Tools](https://python.langchain.com/docs/concepts/tools/) are utilities that can be called by a chat model. In LangChain, creating tools can be done using the `@tool` decorator, which transforms Python functions into callable tools. It will automatically infer the tool's name, description and expected arguments from the function definition. You can also use [Model Context Protocol (MCP) servers](https://github.com/langchain-ai/langchain-mcp-adapters) as LangChain-compatible tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afdff275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def write_email(to: str, subject: str, content: str) -> str:\n",
    "    \"\"\"Write and send an email.\"\"\"\n",
    "    # Placeholder response - in real app would send email\n",
    "    return f\"Email sent to {to} with subject '{subject}' and content: {content}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c52ec55b-0b60-4b0c-95d4-ff528a64694e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.tools.structured.StructuredTool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(write_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23a40647-3d48-4760-aabe-144d627de110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to': {'title': 'To', 'type': 'string'},\n",
       " 'subject': {'title': 'Subject', 'type': 'string'},\n",
       " 'content': {'title': 'Content', 'type': 'string'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_email.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abd85ae4-9d4c-4efa-9577-aca96e9f22cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write and send an email.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_email.description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a6b427",
   "metadata": {},
   "source": [
    "## Tool Calling\n",
    "\n",
    "Tools can be [called](https://python.langchain.com/docs/concepts/tool_calling/) by LLMs. When a tool is bound to the model, the model can choose to call the tool by returning a structured output with tool arguments. We use the `bind_tools` method to augment an LLM with tools.\n",
    "\n",
    "![tool-img](img/tool_call_detail.png)\n",
    "\n",
    "Note that we use the [`tool_choice` parameter](https://python.langchain.com/docs/how_to/tool_choice/) to enforce tool calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfa57bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect tools to a chat model\n",
    "model_with_tools = llm.bind_tools([write_email], tool_choice=\"required\")\n",
    "\n",
    "# The model will now be able to call tools\n",
    "output = model_with_tools.invoke(\"Draft a response to my boss about tomorrow's meeting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "717779cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to': \"[Boss's Email]\",\n",
       " 'subject': \"Re: Tomorrow's Meeting\",\n",
       " 'content': \"Dear [Boss's Name],\\n\\nThank you for the reminder about tomorrow's meeting. I confirm my attendance and will be prepared with the necessary updates and materials.\\n\\nPlease let me know if there is anything specific you would like me to focus on or bring to the discussion.\\n\\nBest regards,\\n[Your Name]\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract tool calls and execute them\n",
    "args = output.tool_calls[0]['args']\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09f85694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email sent to [Boss's Email] with subject 'Re: Tomorrow's Meeting' and content: Dear [Boss's Name],\n",
      "\n",
      "Thank you for the reminder about tomorrow's meeting. I confirm my attendance and will be prepared with the necessary updates and materials.\n",
      "\n",
      "Please let me know if there is anything specific you would like me to focus on or bring to the discussion.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "# Call the tool\n",
    "result = write_email.invoke(args)\n",
    "print(result)  # \"Email to boss@company.com drafted with subject 'Re: Meeting Tomorrow'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f9c52a",
   "metadata": {},
   "source": [
    "Above, we enforce tool calling by setting `tool_choice=\"required\"`, so the model will always call a tool to write an email.\n",
    "\n",
    "![basic_prompt](img/tool_call.png)\n",
    "\n",
    "## Workflows\n",
    " \n",
    "There are many patterns for building applications with LLMs. \n",
    "\n",
    "[We can embed LLM calls into pre-defined workflows](https://langchain-ai.github.io/langgraph/tutorials/workflows/), giving the system more agency to make decisions. \n",
    "\n",
    "As an example, we could add a router step to determine whether to write an email or not.\n",
    "\n",
    "![workflow_example](img/workflow_example.png)\n",
    "\n",
    "## Agents\n",
    "\n",
    "We can further increase agency, allowing the LLM to dynamically direct its own tool usage. \n",
    "\n",
    "[Agents](https://langchain-ai.github.io/langgraph/tutorials/workflows/) are typically implemented as tool calling in a loop, where the output of each tool call is used to inform the next action.\n",
    "\n",
    "![agent_example](img/agent_example.png)\n",
    "\n",
    "Agents are well suited to open-ended problems where it's difficult to predict the *exact* steps needed in advance.\n",
    " \n",
    "Workflows are often appropriate when the control flow can easily be defined in advance. \n",
    "\n",
    "![workflow_v_agent](img/workflow_v_agent.png)\n",
    "\n",
    "## What is LangGraph? \n",
    "\n",
    "[LangGraph](https://langchain-ai.github.io/langgraph/concepts/high_level/) provides low-level supporting infrastructure that sits underneath *any* workflow or agent. \n",
    "\n",
    "It does not abstract prompts or architecture, and provides a few benefits:\n",
    "\n",
    "- **Control**: Make it easy to define and / or combine agents and workflows.\n",
    "- **Persistence**: Provide a way to persist the state of a graph, which enables both memory and human-in-the-loop.\n",
    "- **Testing, Debugging, and Deployment**: Provide an easy onramp for testing, debugging, and deploying applications.\n",
    "\n",
    "### Control\n",
    "\n",
    "LangGraph lets you define your application as a graph with:\n",
    "\n",
    "1. *State*: What information do we need to track over the course of the application?\n",
    "2. *Nodes*: How do we want to update this information over the course of the application?\n",
    "3. *Edges*: How do we want to connect these nodes together?\n",
    "\n",
    "We can use the [`StateGraph` class](https://langchain-ai.github.io/langgraph/concepts/low_level/#graphs) to initialize a LangGraph graph with a [`State` object](https://langchain-ai.github.io/langgraph/concepts/low_level/#state).\n",
    "\n",
    "`State` defines the schema for information we want to track over the course of the application. \n",
    "\n",
    "This can be any object with `getattr()` in python, such as a dictionary, dataclass, or Pydantic object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3319290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class StateSchema(TypedDict):\n",
    "    request: str\n",
    "    email: str\n",
    "\n",
    "workflow = StateGraph(StateSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84bedb9",
   "metadata": {},
   "source": [
    "Each node is simply a python function or typescript code. This gives us full control over the logic inside each node.\n",
    "\n",
    "They receive the current state, and return a dictionary to update the state.\n",
    "\n",
    "By default, [state keys are overwritten](https://langchain-ai.github.io/langgraph/how-tos/state-reducers/). \n",
    "\n",
    "However, you can [define custom update logic](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers). \n",
    "\n",
    "![nodes_edges](img/nodes_edges.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5e79c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_email_node(state: StateSchema) -> StateSchema:\n",
    "    # Imperative code that processes the request\n",
    "    output = model_with_tools.invoke(state[\"request\"])\n",
    "    args = output.tool_calls[0]['args']\n",
    "    email = write_email.invoke(args)\n",
    "    return {\"email\": email}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737c8040",
   "metadata": {},
   "source": [
    "Edges connect nodes together. \n",
    "\n",
    "We specify the control flow by adding edges and nodes to our state graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "554e0d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(StateSchema)\n",
    "workflow.add_node(\"write_email_node\", write_email_node)\n",
    "workflow.add_edge(START, \"write_email_node\")\n",
    "workflow.add_edge(\"write_email_node\", END)\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cc79b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'request': \"Draft a response to my boss about tomorrow's meeting\",\n",
       " 'email': \"Email sent to boss@example.com with subject 'Re: Tomorrow's Meeting' and content: Hi [Boss's Name],\\n\\nI hope this message finds you well. I am writing to confirm my attendance at tomorrow's meeting. Please let me know if there are any specific topics or materials you would like me to prepare in advance.\\n\\nLooking forward to our discussion.\\n\\nBest regards,\\n\\n[Your Name]\"}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"request\": \"Draft a response to my boss about tomorrow's meeting\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2446dea9",
   "metadata": {},
   "source": [
    "Routing between nodes can be done [conditionally](https://langchain-ai.github.io/langgraph/concepts/low_level/#conditional-edges) using a simple function. \n",
    "\n",
    "The return value of this function is used as the name of the node (or list of nodes) to send the state to next. \n",
    "\n",
    "You can optionally provide a dictionary that maps the `should_continue` output to the name of the next node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29b05bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "def call_llm(state: MessagesState) -> MessagesState:\n",
    "    \"\"\"Run LLM\"\"\"\n",
    "\n",
    "    output = model_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [output]}\n",
    "\n",
    "def run_tool(state: dict):\n",
    "    \"\"\"Performs the tool call\"\"\"\n",
    "\n",
    "    result = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        observation = write_email.invoke(tool_call[\"args\"])\n",
    "        result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": tool_call[\"id\"]})\n",
    "    return {\"messages\": result}\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"run_tool\", END]:\n",
    "    \"\"\"Route to tool handler, or end if Done tool called\"\"\"\n",
    "    \n",
    "    # Get the last message\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # If the last message is a tool call, check if it's a Done tool call\n",
    "    if last_message.tool_calls:\n",
    "        return \"run_tool\"\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"call_llm\", call_llm)\n",
    "workflow.add_node(\"run_tool\", run_tool)\n",
    "workflow.add_edge(START, \"call_llm\")\n",
    "workflow.add_conditional_edges(\"call_llm\", should_continue, {\"run_tool\": \"run_tool\", END: END})\n",
    "workflow.add_edge(\"run_tool\", END)\n",
    "\n",
    "# Run the workflow\n",
    "app = workflow.compile()\n",
    "\n",
    "try:\n",
    "    # The API for mermaid diagrams has been unstable, so we can fallback to pyppeteer to draw the diagram\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "    display(Image(app.get_graph().draw_mermaid_png(draw_method=MermaidDrawMethod.PYPPETEER)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dadbafde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"Draft a response to my boss about tomorrow's meeting\", additional_kwargs={}, response_metadata={}, id='5e2d9fe3-c075-47ba-a253-f06ffb67aab5'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_iIS382COCMtqYtfwIfBBf8P9', 'function': {'arguments': '{\"to\":\"boss@example.com\",\"subject\":\"Re: Tomorrow\\'s Meeting\",\"content\":\"Hi [Boss\\'s Name],\\\\n\\\\nI hope this message finds you well. I am writing to confirm my attendance at tomorrow\\'s meeting. Please let me know if there are any specific topics or materials you would like me to prepare in advance.\\\\n\\\\nLooking forward to our discussion.\\\\n\\\\nBest regards,\\\\n\\\\n[Your Name]\"}', 'name': 'write_email'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 61, 'total_tokens': 158, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_90122d973c', 'id': 'chatcmpl-BTwquc2LNqLegxeH93d9gDyD3tRcf', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ded32fbe-2094-4a9d-93ca-8e3bd79b35f0-0', tool_calls=[{'name': 'write_email', 'args': {'to': 'boss@example.com', 'subject': \"Re: Tomorrow's Meeting\", 'content': \"Hi [Boss's Name],\\n\\nI hope this message finds you well. I am writing to confirm my attendance at tomorrow's meeting. Please let me know if there are any specific topics or materials you would like me to prepare in advance.\\n\\nLooking forward to our discussion.\\n\\nBest regards,\\n\\n[Your Name]\"}, 'id': 'call_iIS382COCMtqYtfwIfBBf8P9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 61, 'output_tokens': 97, 'total_tokens': 158, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content=\"Email sent to boss@example.com with subject 'Re: Tomorrow's Meeting' and content: Hi [Boss's Name],\\n\\nI hope this message finds you well. I am writing to confirm my attendance at tomorrow's meeting. Please let me know if there are any specific topics or materials you would like me to prepare in advance.\\n\\nLooking forward to our discussion.\\n\\nBest regards,\\n\\n[Your Name]\", id='d77958ea-98d9-40fb-8771-c91924a81bdc', tool_call_id='call_iIS382COCMtqYtfwIfBBf8P9')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = app.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Draft a response to my boss about tomorrow's meeting\"}]})\n",
    "result[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78b232d",
   "metadata": {},
   "source": [
    "With these low level components, you can build many many different workflows and agents. See [this tutorial](https://langchain-ai.github.io/langgraph/tutorials/workflows/)!\n",
    "\n",
    "Because agents are such a common pattern, [LangGraph](https://langchain-ai.github.io/langgraph/tutorials/workflows/#pre-built) has [a pre-built agent](https://langchain-ai.github.io/langgraph/agents/overview/?ref=blog.langchain.dev#what-is-an-agent) abstraction.\n",
    "\n",
    "With LangGraph's [pre-built method](https://langchain-ai.github.io/langgraph/tutorials/workflows/#pre-built), we just pass in the LLM, tools, and prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a317ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"Draft a response to my boss about tomorrow's meeting\", additional_kwargs={}, response_metadata={}, id='b38b8654-8947-4f76-9d33-a3c30bb1ad1f'),\n",
       "  AIMessage(content='Of course! Could you please provide a bit more detail? For example:\\n\\n- What is the purpose or topic of the meeting?\\n- Do you want to confirm your attendance, ask to reschedule, or provide any specific information?\\n- Is there a particular tone you’d like (formal, friendly, etc.)?\\n\\nLet me know so I can tailor the response to your needs!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 78, 'prompt_tokens': 71, 'total_tokens': 149, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_cf18407276', 'id': 'chatcmpl-BUJdSwIfBhV1zKy9CFFuAzRnGAAHv', 'finish_reason': 'stop', 'logprobs': None}, id='run-25f15909-fe23-4630-9921-00c292e64b0c-0', usage_metadata={'input_tokens': 71, 'output_tokens': 78, 'total_tokens': 149, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[write_email],\n",
    "    prompt=\"Respond to the user's request using the tools provided.\"  \n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Draft a response to my boss about tomorrow's meeting\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6e506f",
   "metadata": {},
   "source": [
    "### Persistence\n",
    "\n",
    "It can be very useful to allow agents to pause and gather human feedback.\n",
    "\n",
    "LangGraph has a built-in persistence layer, implemented through checkpointers, to enable this. \n",
    "\n",
    "When you compile graph with a checkpointer, the checkpointer saves a [checkpoint](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpoints) of the graph state at every step. \n",
    "\n",
    "Checkpoints are saved to a thread, which can be accessed after graph execution.\n",
    "\n",
    "![checkpointer](img/checkpoints.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a72377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[write_email],\n",
    "    prompt=\"Respond to the user's request using the tools provided.\",\n",
    "    checkpointer=InMemorySaver()\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What are some good practices for writing emails?\"}]}, config)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10984007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are some good practices for writing emails?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here are some good practices for writing effective emails:\n",
      "\n",
      "1. **Use a Clear Subject Line:** Make your subject concise and informative so the recipient knows what to expect.\n",
      "\n",
      "2. **Greet Appropriately:** Start with a polite greeting, using the recipient’s name if possible.\n",
      "\n",
      "3. **Be Concise and to the Point:** State your purpose early and keep your message focused.\n",
      "\n",
      "4. **Use Proper Grammar and Spelling:** Proofread your email to avoid errors and maintain professionalism.\n",
      "\n",
      "5. **Structure Your Email:** Use short paragraphs, bullet points, or numbered lists for clarity.\n",
      "\n",
      "6. **Be Polite and Professional:** Use courteous language and avoid slang or overly casual expressions.\n",
      "\n",
      "7. **Include a Call to Action:** Clearly state what you need from the recipient, if applicable.\n",
      "\n",
      "8. **Sign Off Properly:** End with a polite closing (e.g., “Best regards,” “Sincerely”) and your name.\n",
      "\n",
      "9. **Use a Professional Email Address:** Ensure your email address is appropriate for business communication.\n",
      "\n",
      "10. **Check Attachments:** If you mention attachments, make sure they are included before sending.\n",
      "\n",
      "Would you like tips for a specific type of email (e.g., business, networking, follow-up)?\n"
     ]
    }
   ],
   "source": [
    "# Get the latest state snapshot\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "state = agent.get_state(config)\n",
    "for message in state.values['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f23ac58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are some good practices for writing emails?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here are some good practices for writing effective emails:\n",
      "\n",
      "1. **Use a Clear Subject Line:** Make your subject concise and informative so the recipient knows what to expect.\n",
      "\n",
      "2. **Greet Appropriately:** Start with a polite greeting, using the recipient’s name if possible.\n",
      "\n",
      "3. **Be Concise and to the Point:** State your purpose early and keep your message focused.\n",
      "\n",
      "4. **Use Proper Grammar and Spelling:** Proofread your email to avoid errors and maintain professionalism.\n",
      "\n",
      "5. **Structure Your Email:** Use short paragraphs, bullet points, or numbered lists for clarity.\n",
      "\n",
      "6. **Be Polite and Professional:** Use courteous language and avoid slang or overly casual expressions.\n",
      "\n",
      "7. **Include a Call to Action:** Clearly state what you need from the recipient, if applicable.\n",
      "\n",
      "8. **Sign Off Properly:** End with a polite closing (e.g., “Best regards,” “Sincerely”) and your name.\n",
      "\n",
      "9. **Use a Professional Email Address:** Ensure your email address is appropriate for business communication.\n",
      "\n",
      "10. **Check Attachments:** If you mention attachments, make sure they are included before sending.\n",
      "\n",
      "Would you like tips for a specific type of email (e.g., business, networking, follow-up)?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Good, let's use lesson 3 to craft a response to my boss about tomorrow's meeting\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Absolutely! Lesson 3 is: **Be Concise and to the Point: State your purpose early and keep your message focused.**\n",
      "\n",
      "Here’s a concise and focused sample response to your boss about tomorrow’s meeting:\n",
      "\n",
      "---\n",
      "\n",
      "**Subject:** Re: Tomorrow’s Meeting\n",
      "\n",
      "Hi [Boss’s Name],\n",
      "\n",
      "Thank you for the update about tomorrow’s meeting. I confirm my attendance and will be prepared with the requested materials.\n",
      "\n",
      "Please let me know if there’s anything specific you’d like me to address.\n",
      "\n",
      "Best regards,  \n",
      "[Your Name]\n",
      "\n",
      "---\n",
      "\n",
      "Would you like to personalize this further or add any specific details?\n"
     ]
    }
   ],
   "source": [
    "# Continue the conversation\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Good, let's use lesson 3 to craft a response to my boss about tomorrow's meeting\"}]}, config)\n",
    "for m in result['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f09fe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are some good practices for writing emails?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here are some good practices for writing effective emails:\n",
      "\n",
      "1. **Use a Clear Subject Line:** Make your subject concise and informative so the recipient knows what to expect.\n",
      "\n",
      "2. **Greet Appropriately:** Start with a polite greeting, using the recipient’s name if possible.\n",
      "\n",
      "3. **Be Concise and to the Point:** State your purpose early and keep your message focused.\n",
      "\n",
      "4. **Use Proper Grammar and Spelling:** Proofread your email to avoid errors and maintain professionalism.\n",
      "\n",
      "5. **Structure Your Email:** Use short paragraphs, bullet points, or numbered lists for clarity.\n",
      "\n",
      "6. **Be Polite and Professional:** Use courteous language and avoid slang or overly casual expressions.\n",
      "\n",
      "7. **Include a Call to Action:** Clearly state what you need from the recipient, if applicable.\n",
      "\n",
      "8. **Sign Off Properly:** End with a polite closing (e.g., “Best regards,” “Sincerely”) and your name.\n",
      "\n",
      "9. **Use a Professional Email Address:** Ensure your email address is appropriate for business communication.\n",
      "\n",
      "10. **Check Attachments:** If you mention attachments, make sure they are included before sending.\n",
      "\n",
      "Would you like tips for a specific type of email (e.g., business, networking, follow-up)?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Good, let's use lesson 3 to craft a response to my boss about tomorrow's meeting\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Absolutely! Lesson 3 is: **Be Concise and to the Point: State your purpose early and keep your message focused.**\n",
      "\n",
      "Here’s a concise and focused sample response to your boss about tomorrow’s meeting:\n",
      "\n",
      "---\n",
      "\n",
      "**Subject:** Re: Tomorrow’s Meeting\n",
      "\n",
      "Hi [Boss’s Name],\n",
      "\n",
      "Thank you for the update about tomorrow’s meeting. I confirm my attendance and will be prepared with the requested materials.\n",
      "\n",
      "Please let me know if there’s anything specific you’d like me to address.\n",
      "\n",
      "Best regards,  \n",
      "[Your Name]\n",
      "\n",
      "---\n",
      "\n",
      "Would you like to personalize this further or add any specific details?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like this, let's write the email\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  write_email (call_SwjJrNjGBTjpTLIhByhohrby)\n",
      " Call ID: call_SwjJrNjGBTjpTLIhByhohrby\n",
      "  Args:\n",
      "    to: [Boss’s Email]\n",
      "    subject: Re: Tomorrow’s Meeting\n",
      "    content: Hi [Boss’s Name],\n",
      "\n",
      "Thank you for the update about tomorrow’s meeting. I confirm my attendance and will be prepared with the requested materials.\n",
      "\n",
      "Please let me know if there’s anything specific you’d like me to address.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: write_email\n",
      "\n",
      "Email sent to [Boss’s Email] with subject 'Re: Tomorrow’s Meeting' and content: Hi [Boss’s Name],\n",
      "\n",
      "Thank you for the update about tomorrow’s meeting. I confirm my attendance and will be prepared with the requested materials.\n",
      "\n",
      "Please let me know if there’s anything specific you’d like me to address.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The email has been drafted and sent with a concise, focused response confirming your attendance at tomorrow’s meeting. If you’d like to personalize it further (with your boss’s name or your own), just let me know!\n"
     ]
    }
   ],
   "source": [
    "# Continue the conversation\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"I like this, let's write the email\"}]}, config)\n",
    "for m in result['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8639a518",
   "metadata": {},
   "source": [
    "### Testing, Debugging, and Deployment\n",
    "\n",
    "When we are using LangChain or LangGraph, LangSmith logging [will work out of the box](https://docs.smith.langchain.com/observability/how_to_guides/trace_with_langgraph) with the following environment variables set:\n",
    "\n",
    "```\n",
    "export LANGSMITH_TRACING=true\n",
    "export LANGSMITH_API_KEY=\"<your-langsmith-api-key>\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f864ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"LANGSMITH_TRACING\")\n",
    "_set_env(\"LANGSMITH_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb2a3e5",
   "metadata": {},
   "source": [
    "Here is the LangSmith trace from above graph execution:\n",
    "\n",
    "https://smith.langchain.com/public/6f77014f-d054-44ed-aa2c-8b06ceab689f/r\n",
    "\n",
    "We can see that the agent is able to continue the conversation from the previous state because we used a checkpointer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0269214",
   "metadata": {},
   "source": [
    "It's also easy to deploy to deploy our graph using [LangGraph Platform](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/). \n",
    "\n",
    "We simply need to ensure our project has [a structure](https://langchain-ai.github.io/langgraph/concepts/application_structure/) like this:\n",
    "\n",
    "```\n",
    "my-app/\n",
    "├── my_agent # all project code lies within here\n",
    "│   └── agent.py # code for constructing your graph\n",
    "├── .env # environment variables\n",
    "├── langgraph.json  # configuration file for LangGraph\n",
    "└── pyproject.toml # dependencies for your project\n",
    "```\n",
    "\n",
    "The `langgraph.json` file specifies the dependencies, graphs, environment variables, and other settings required to deploy a LangGraph application.\n",
    "\n",
    "To test this, let's deploy `langgraph_101.py`. We have it in our `langgraph.json` file in this repo:\n",
    "\n",
    "```\n",
    " \"langgraph101\": \"./src/email_assistant/langgraph101.py:app\",\n",
    "```\n",
    "\n",
    "There are a range of [deployment options](https://langchain-ai.github.io/langgraph/tutorials/deployment/). \n",
    "\n",
    "* All create an API [server](https://langchain-ai.github.io/langgraph/concepts/langgraph_server/) for our graph\n",
    "* All include an interactive IDE (LangGraph [Studio](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/)).\n",
    " \n",
    "We can start a deployment locally using `langgraph dev`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf38d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "! langgraph dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3644093",
   "metadata": {},
   "source": [
    "Here we can see a visualization of the graph as well as the graph state in Studio.\n",
    "\n",
    "![langgraph_studio](img/langgraph_studio.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226a3f4a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
